"""
æ•°æ®è½¬æ¢å·¥å…·æ¨¡å—
æä¾›å„ç§æ ‡æ³¨æ ¼å¼ä¹‹é—´çš„è½¬æ¢åŠŸèƒ½
"""

import json
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import List, Dict, Union, Optional
import shutil
import random
from PIL import Image

# å°è¯•ç›¸å¯¹å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    from .logger import get_logger
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))

    from yoloserver.utils.logger import get_logger

logger = get_logger(__name__)


def ensure_dir(path: Union[str, Path]) -> None:
    """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    Path(path).mkdir(parents=True, exist_ok=True)

class AnnotationConverter:
    """æ ‡æ³¨æ ¼å¼è½¬æ¢å™¨åŸºç±»"""
    
    def __init__(self):
        self.class_names = []
        self.class_to_id = {}
        self.id_to_class = {}
    
    def set_classes(self, class_names: List[str]):
        """è®¾ç½®ç±»åˆ«åç§°"""
        self.class_names = class_names
        self.class_to_id = {name: idx for idx, name in enumerate(class_names)}
        self.id_to_class = {idx: name for idx, name in enumerate(class_names)}

class COCOToYOLOConverter(AnnotationConverter):
    """COCOæ ¼å¼åˆ°YOLOæ ¼å¼è½¬æ¢å™¨"""
    
    def convert_annotation_file(self, coco_json_path: Union[str, Path], 
                              output_dir: Union[str, Path]) -> bool:
        """
        è½¬æ¢COCO JSONæ–‡ä»¶åˆ°YOLOæ ¼å¼
        
        Args:
            coco_json_path: COCO JSONæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        try:
            with open(coco_json_path, 'r', encoding='utf-8') as f:
                coco_data = json.load(f)
            
            # æå–ç±»åˆ«ä¿¡æ¯
            categories = coco_data.get('categories', [])
            class_names = [cat['name'] for cat in categories]
            self.set_classes(class_names)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path(output_dir)
            ensure_dir(output_dir)
            
            # åˆ›å»ºå›¾åƒIDåˆ°æ–‡ä»¶åçš„æ˜ å°„
            images = coco_data.get('images', [])
            image_id_to_info = {img['id']: img for img in images}
            
            # æŒ‰å›¾åƒåˆ†ç»„æ ‡æ³¨
            annotations = coco_data.get('annotations', [])
            image_annotations = {}
            for ann in annotations:
                image_id = ann['image_id']
                if image_id not in image_annotations:
                    image_annotations[image_id] = []
                image_annotations[image_id].append(ann)
            
            # è½¬æ¢æ¯ä¸ªå›¾åƒçš„æ ‡æ³¨
            for image_id, anns in image_annotations.items():
                if image_id not in image_id_to_info:
                    continue
                
                image_info = image_id_to_info[image_id]
                image_width = image_info['width']
                image_height = image_info['height']
                image_filename = Path(image_info['file_name']).stem
                
                # è½¬æ¢æ ‡æ³¨
                yolo_lines = []
                for ann in anns:
                    bbox = ann['bbox']  # [x, y, width, height]
                    category_id = ann['category_id']
                    
                    # è½¬æ¢ä¸ºYOLOæ ¼å¼
                    yolo_bbox = self._coco_bbox_to_yolo(bbox, image_width, image_height)
                    yolo_class_id = self._coco_category_to_yolo_class(category_id, categories)
                    
                    yolo_line = f"{yolo_class_id} {' '.join(map(str, yolo_bbox))}"
                    yolo_lines.append(yolo_line)
                
                # ä¿å­˜YOLOæ ‡æ³¨æ–‡ä»¶
                output_file = output_dir / f"{image_filename}.txt"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(yolo_lines))
            
            logger.info(f"æˆåŠŸè½¬æ¢COCOæ ‡æ³¨åˆ°YOLOæ ¼å¼ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
            return True
            
        except Exception as e:
            logger.error(f"COCOåˆ°YOLOè½¬æ¢å¤±è´¥: {e}")
            return False
    
    def _coco_bbox_to_yolo(self, coco_bbox: List[float], 
                          image_width: int, image_height: int) -> List[float]:
        """å°†COCOè¾¹ç•Œæ¡†è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        x, y, width, height = coco_bbox
        
        # è®¡ç®—ä¸­å¿ƒç‚¹åæ ‡
        center_x = x + width / 2
        center_y = y + height / 2
        
        # å½’ä¸€åŒ–
        center_x /= image_width
        center_y /= image_height
        width /= image_width
        height /= image_height
        
        return [center_x, center_y, width, height]
    
    def _coco_category_to_yolo_class(self, category_id: int, categories: List[Dict]) -> int:
        """å°†COCOç±»åˆ«IDè½¬æ¢ä¸ºYOLOç±»åˆ«ID"""
        for idx, cat in enumerate(categories):
            if cat['id'] == category_id:
                return idx
        return 0

class PascalVOCToYOLOConverter(AnnotationConverter):
    """Pascal VOCæ ¼å¼åˆ°YOLOæ ¼å¼è½¬æ¢å™¨"""
    
    def convert_annotation_file(self, xml_path: Union[str, Path], 
                              output_path: Union[str, Path],
                              image_width: int, image_height: int) -> bool:
        """
        è½¬æ¢å•ä¸ªPascal VOC XMLæ–‡ä»¶åˆ°YOLOæ ¼å¼
        
        Args:
            xml_path: XMLæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            image_width: å›¾åƒå®½åº¦
            image_height: å›¾åƒé«˜åº¦
            
        Returns:
            bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()
            
            yolo_lines = []
            
            for obj in root.findall('object'):
                class_name = obj.find('name').text
                if class_name not in self.class_to_id:
                    logger.warning(f"æœªçŸ¥ç±»åˆ«: {class_name}")
                    continue
                
                class_id = self.class_to_id[class_name]
                
                bbox = obj.find('bndbox')
                xmin = float(bbox.find('xmin').text)
                ymin = float(bbox.find('ymin').text)
                xmax = float(bbox.find('xmax').text)
                ymax = float(bbox.find('ymax').text)
                
                # è½¬æ¢ä¸ºYOLOæ ¼å¼
                center_x = (xmin + xmax) / 2 / image_width
                center_y = (ymin + ymax) / 2 / image_height
                width = (xmax - xmin) / image_width
                height = (ymax - ymin) / image_height
                
                yolo_line = f"{class_id} {center_x} {center_y} {width} {height}"
                yolo_lines.append(yolo_line)
            
            # ä¿å­˜YOLOæ ‡æ³¨æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(yolo_lines))
            
            return True
            
        except Exception as e:
            logger.error(f"Pascal VOCåˆ°YOLOè½¬æ¢å¤±è´¥: {e}")
            return False

def convert_coco_to_yolo(coco_json_path: Union[str, Path], 
                        output_dir: Union[str, Path]) -> bool:
    """
    è½¬æ¢COCOæ ¼å¼æ ‡æ³¨åˆ°YOLOæ ¼å¼
    
    Args:
        coco_json_path: COCO JSONæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    converter = COCOToYOLOConverter()
    return converter.convert_annotation_file(coco_json_path, output_dir)

def convert_pascal_to_yolo(xml_dir: Union[str, Path], 
                          output_dir: Union[str, Path],
                          class_names: List[str],
                          image_dir: Optional[Union[str, Path]] = None) -> bool:
    """
    æ‰¹é‡è½¬æ¢Pascal VOCæ ¼å¼æ ‡æ³¨åˆ°YOLOæ ¼å¼
    
    Args:
        xml_dir: XMLæ–‡ä»¶ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        image_dir: å›¾åƒç›®å½•ï¼Œç”¨äºè·å–å›¾åƒå°ºå¯¸
        
    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    try:
        xml_dir = Path(xml_dir)
        output_dir = Path(output_dir)
        ensure_dir(output_dir)
        
        converter = PascalVOCToYOLOConverter()
        converter.set_classes(class_names)
        
        xml_files = list(xml_dir.glob("*.xml"))
        
        for xml_file in xml_files:
            # è·å–å¯¹åº”çš„å›¾åƒæ–‡ä»¶
            image_file = None
            if image_dir:
                image_dir = Path(image_dir)
                for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                    potential_image = image_dir / f"{xml_file.stem}{ext}"
                    if potential_image.exists():
                        image_file = potential_image
                        break
            
            # è·å–å›¾åƒå°ºå¯¸
            if image_file and image_file.exists():
                with Image.open(image_file) as img:
                    image_width, image_height = img.size
            else:
                # å¦‚æœæ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶ï¼Œå°è¯•ä»XMLä¸­è¯»å–å°ºå¯¸
                tree = ET.parse(xml_file)
                root = tree.getroot()
                size = root.find('size')
                if size is not None:
                    image_width = int(size.find('width').text)
                    image_height = int(size.find('height').text)
                else:
                    logger.warning(f"æ— æ³•è·å–å›¾åƒå°ºå¯¸: {xml_file}")
                    continue
            
            # è½¬æ¢æ ‡æ³¨
            output_file = output_dir / f"{xml_file.stem}.txt"
            converter.convert_annotation_file(xml_file, output_file, image_width, image_height)
        
        logger.info(f"æˆåŠŸè½¬æ¢{len(xml_files)}ä¸ªPascal VOCæ ‡æ³¨æ–‡ä»¶åˆ°YOLOæ ¼å¼")
        return True

    except Exception as e:
        logger.error(f"Pascal VOCåˆ°YOLOæ‰¹é‡è½¬æ¢å¤±è´¥: {e}")
        return False

def organize_valid_pairs(image_dir: Union[str, Path],
                        label_dir: Union[str, Path],
                        output_dir: Union[str, Path]) -> bool:
    """
    æ•´ç†æœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹åˆ°processedç›®å½•

    Args:
        image_dir: åŸå§‹å›¾åƒç›®å½•
        label_dir: æ ‡ç­¾ç›®å½•
        output_dir: è¾“å‡ºç›®å½•(processed)

    Returns:
        bool: æ•´ç†æ˜¯å¦æˆåŠŸ
    """
    try:
        image_dir = Path(image_dir)
        label_dir = Path(label_dir)
        output_dir = Path(output_dir)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_images_dir = output_dir / 'images'
        output_labels_dir = output_dir / 'labels'
        ensure_dir(output_images_dir)
        ensure_dir(output_labels_dir)

        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP']
        image_files = []
        for ext in image_extensions:
            image_files.extend(image_dir.glob(f"*{ext}"))

        # å»é‡
        image_files = list(set(image_files))

        if not image_files:
            logger.error(f"åœ¨{image_dir}ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return False

        # è¿‡æ»¤æœ‰å¯¹åº”æ ‡ç­¾æ–‡ä»¶çš„å›¾åƒ
        valid_pairs = []
        for image_file in image_files:
            label_file = label_dir / f"{image_file.stem}.txt"
            if label_file.exists():
                valid_pairs.append((image_file, label_file))

        if not valid_pairs:
            logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹")
            return False

        logger.info(f"æ‰¾åˆ°{len(valid_pairs)}ä¸ªæœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹")

        # å¤åˆ¶æœ‰æ•ˆçš„å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶
        for image_file, label_file in valid_pairs:
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            dst_image = output_images_dir / image_file.name
            shutil.copy2(image_file, dst_image)

            # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
            dst_label = output_labels_dir / label_file.name
            shutil.copy2(label_file, dst_label)

        logger.info(f"æœ‰æ•ˆæ•°æ®æ•´ç†å®Œæˆï¼Œè¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"æœ‰æ•ˆå›¾åƒ: {len(valid_pairs)}å¼ ")
        return True

    except Exception as e:
        logger.error(f"æœ‰æ•ˆæ•°æ®æ•´ç†å¤±è´¥: {e}")
        return False


def split_dataset(image_dir: Union[str, Path],
                 label_dir: Union[str, Path],
                 output_dir: Union[str, Path],
                 train_ratio: float = 0.7,
                 val_ratio: float = 0.2,
                 test_ratio: float = 0.1,
                 seed: int = 42,
                 stratify: bool = True) -> bool:
    """
    åˆ†å‰²æ•°æ®é›†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†

    Args:
        image_dir: å›¾åƒç›®å½•
        label_dir: æ ‡ç­¾ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
        seed: éšæœºç§å­
        stratify: æ˜¯å¦ä½¿ç”¨åˆ†å±‚åˆ†å‰²ï¼ˆæŒ‰ç±»åˆ«æ¯”ä¾‹åˆ†å‰²ï¼‰ï¼Œé»˜è®¤True

    Returns:
        bool: åˆ†å‰²æ˜¯å¦æˆåŠŸ
    """
    try:
        image_dir = Path(image_dir)
        label_dir = Path(label_dir)
        output_dir = Path(output_dir)

        # æ£€æŸ¥æ¯”ä¾‹æ€»å’Œ
        if abs(train_ratio + val_ratio + test_ratio - 1.0) > 1e-6:
            logger.error("è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º1.0")
            return False

        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP']
        image_files = []
        for ext in image_extensions:
            image_files.extend(image_dir.glob(f"*{ext}"))

        # å»é‡ï¼ˆé˜²æ­¢Windowsç³»ç»Ÿå¤§å°å†™ä¸æ•æ„Ÿå¯¼è‡´çš„é‡å¤ï¼‰
        image_files = list(set(image_files))

        if not image_files:
            logger.error(f"åœ¨{image_dir}ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return False

        # è¿‡æ»¤æœ‰å¯¹åº”æ ‡ç­¾æ–‡ä»¶çš„å›¾åƒ
        valid_pairs = []
        for image_file in image_files:
            label_file = label_dir / f"{image_file.stem}.txt"
            if label_file.exists():
                valid_pairs.append((image_file, label_file))

        if not valid_pairs:
            logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹")
            return False

        logger.info(f"æ‰¾åˆ°{len(valid_pairs)}ä¸ªæœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹")

        # æ¸…ç†ä¹‹å‰çš„è¾“å‡ºç›®å½•
        if output_dir.exists():
            logger.info("æ¸…ç†ä¹‹å‰çš„åˆ†å‰²æ•°æ®...")
            for split_name in ['train', 'val', 'test']:
                split_dir = output_dir / split_name
                if split_dir.exists():
                    shutil.rmtree(split_dir)
                    logger.info(f"å·²æ¸…ç†: {split_dir}")

        # æ ¹æ®stratifyå‚æ•°é€‰æ‹©åˆ†å‰²æ–¹å¼
        if stratify:
            logger.info("ä½¿ç”¨åˆ†å±‚åˆ†å‰²ï¼ˆæŒ‰ç±»åˆ«æ¯”ä¾‹åˆ†å‰²ï¼‰")
            return _stratified_split(valid_pairs, train_ratio, val_ratio, test_ratio, seed, output_dir)
        else:
            logger.info("ä½¿ç”¨éšæœºåˆ†å‰²")
            return _random_split(valid_pairs, train_ratio, val_ratio, test_ratio, seed, output_dir)

    except Exception as e:
        logger.error(f"æ•°æ®é›†åˆ†å‰²å¤±è´¥: {e}")
        return False


def _stratified_split(valid_pairs: List[tuple],
                     train_ratio: float,
                     val_ratio: float,
                     test_ratio: float,
                     seed: int,
                     output_dir: Path) -> bool:
    """
    åˆ†å±‚åˆ†å‰²ï¼šæŒ‰ç±»åˆ«æ¯”ä¾‹åˆ†å‰²æ•°æ®é›†

    Args:
        valid_pairs: æœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹åˆ—è¡¨
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
        seed: éšæœºç§å­
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        bool: åˆ†å‰²æ˜¯å¦æˆåŠŸ
    """
    from collections import defaultdict

    try:
        # æŒ‰ç±»åˆ«åˆ†ç»„
        class_groups = defaultdict(list)
        class_names = {0: 'objects', 1: 'glioma_tumor', 2: 'meningioma_tumor', 3: 'pituitary_tumor'}

        for image_file, label_file in valid_pairs:
            # è¯»å–æ ‡æ³¨æ–‡ä»¶è·å–ä¸»è¦ç±»åˆ«ï¼ˆå–ç¬¬ä¸€ä¸ªæ ‡æ³¨çš„ç±»åˆ«ï¼‰
            try:
                with open(label_file, 'r', encoding='utf-8') as f:
                    first_line = f.readline().strip()
                    if first_line:
                        class_id = int(first_line.split()[0])
                        class_groups[class_id].append((image_file, label_file))
                    else:
                        # å¦‚æœæ ‡æ³¨æ–‡ä»¶ä¸ºç©ºï¼Œå½’ç±»åˆ°objectsç±»åˆ«
                        class_groups[0].append((image_file, label_file))
            except (ValueError, IndexError) as e:
                logger.warning(f"è§£ææ ‡æ³¨æ–‡ä»¶å¤±è´¥ {label_file}: {e}ï¼Œå½’ç±»åˆ°objectsç±»åˆ«")
                class_groups[0].append((image_file, label_file))

        # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
        logger.info("åŸå§‹æ•°æ®ç±»åˆ«åˆ†å¸ƒ:")
        total_samples = 0
        for class_id, pairs in class_groups.items():
            class_name = class_names.get(class_id, f'class_{class_id}')
            logger.info(f"  {class_name} (ID:{class_id}): {len(pairs)} ä¸ªæ ·æœ¬")
            total_samples += len(pairs)

        # å¯¹æ¯ä¸ªç±»åˆ«åˆ†åˆ«åˆ†å‰²
        train_pairs, val_pairs, test_pairs = [], [], []

        for class_id, pairs in class_groups.items():
            if not pairs:
                continue

            # è®¾ç½®éšæœºç§å­å¹¶æ‰“ä¹±
            random.seed(seed + class_id)  # æ¯ä¸ªç±»åˆ«ä½¿ç”¨ä¸åŒçš„ç§å­
            random.shuffle(pairs)

            total = len(pairs)
            train_count = max(1, int(total * train_ratio))  # è‡³å°‘ä¿è¯1ä¸ªæ ·æœ¬
            val_count = max(0, int(total * val_ratio))
            test_count = total - train_count - val_count

            # åˆ†å‰²å½“å‰ç±»åˆ«çš„æ•°æ®
            class_train = pairs[:train_count]
            class_val = pairs[train_count:train_count + val_count]
            class_test = pairs[train_count + val_count:]

            train_pairs.extend(class_train)
            val_pairs.extend(class_val)
            test_pairs.extend(class_test)

            class_name = class_names.get(class_id, f'class_{class_id}')
            logger.info(f"  {class_name}: è®­ç»ƒ{len(class_train)}, éªŒè¯{len(class_val)}, æµ‹è¯•{len(class_test)}")

        # æœ€åéšæœºæ‰“ä¹±å„ä¸ªæ•°æ®é›†ï¼ˆä¿æŒç±»åˆ«åˆ†å¸ƒçš„åŒæ—¶å¢åŠ éšæœºæ€§ï¼‰
        random.seed(seed)
        random.shuffle(train_pairs)
        random.shuffle(val_pairs)
        random.shuffle(test_pairs)

        # éªŒè¯åˆ†å‰²ç»“æœ
        total_split = len(train_pairs) + len(val_pairs) + len(test_pairs)
        logger.info(f"åˆ†å±‚åˆ†å‰²å®Œæˆ: æ€»æ ·æœ¬{total_samples}, åˆ†å‰²å{total_split}")
        logger.info(f"æœ€ç»ˆåˆ†å¸ƒ: è®­ç»ƒ{len(train_pairs)}, éªŒè¯{len(val_pairs)}, æµ‹è¯•{len(test_pairs)}")

        if total_split != total_samples:
            logger.error(f"åˆ†å‰²é”™è¯¯: æ€»æ ·æœ¬æ•°ä¸åŒ¹é…! åŸå§‹:{total_samples}, åˆ†å‰²å:{total_split}")
            return False

        # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
        return _copy_files_to_splits(train_pairs, val_pairs, test_pairs, output_dir)

    except Exception as e:
        logger.error(f"åˆ†å±‚åˆ†å‰²å¤±è´¥: {e}")
        return False


def _random_split(valid_pairs: List[tuple],
                 train_ratio: float,
                 val_ratio: float,
                 test_ratio: float,
                 seed: int,
                 output_dir: Path) -> bool:
    """
    éšæœºåˆ†å‰²ï¼šéšæœºåˆ†å‰²æ•°æ®é›†

    Args:
        valid_pairs: æœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹åˆ—è¡¨
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
        seed: éšæœºç§å­
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        bool: åˆ†å‰²æ˜¯å¦æˆåŠŸ
    """
    try:
        # éšæœºæ‰“ä¹±
        random.seed(seed)
        random.shuffle(valid_pairs)

        # è®¡ç®—åˆ†å‰²ç‚¹
        total_count = len(valid_pairs)
        train_count = int(total_count * train_ratio)
        val_count = int(total_count * val_ratio)
        # test_count = total_count - train_count - val_count  # è‡ªåŠ¨è®¡ç®—

        # åˆ†å‰²æ•°æ®
        train_pairs = valid_pairs[:train_count]
        val_pairs = valid_pairs[train_count:train_count + val_count]
        test_pairs = valid_pairs[train_count + val_count:]

        # éªŒè¯åˆ†å‰²ç»“æœ
        total_split = len(train_pairs) + len(val_pairs) + len(test_pairs)
        logger.info(f"éšæœºåˆ†å‰²å®Œæˆ: æ€»æ ·æœ¬{total_count}, åˆ†å‰²å{total_split}")
        logger.info(f"æœ€ç»ˆåˆ†å¸ƒ: è®­ç»ƒ{len(train_pairs)}, éªŒè¯{len(val_pairs)}, æµ‹è¯•{len(test_pairs)}")

        if total_split != total_count:
            logger.error(f"åˆ†å‰²é”™è¯¯: æ€»æ ·æœ¬æ•°ä¸åŒ¹é…! åŸå§‹:{total_count}, åˆ†å‰²å:{total_split}")
            return False

        # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
        return _copy_files_to_splits(train_pairs, val_pairs, test_pairs, output_dir)

    except Exception as e:
        logger.error(f"éšæœºåˆ†å‰²å¤±è´¥: {e}")
        return False


def _copy_files_to_splits(train_pairs: List[tuple],
                         val_pairs: List[tuple],
                         test_pairs: List[tuple],
                         output_dir: Path) -> bool:
    """
    å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”çš„åˆ†å‰²ç›®å½•

    Args:
        train_pairs: è®­ç»ƒé›†å›¾åƒ-æ ‡ç­¾å¯¹
        val_pairs: éªŒè¯é›†å›¾åƒ-æ ‡ç­¾å¯¹
        test_pairs: æµ‹è¯•é›†å›¾åƒ-æ ‡ç­¾å¯¹
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        bool: å¤åˆ¶æ˜¯å¦æˆåŠŸ
    """
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        splits = {
            'train': train_pairs,
            'val': val_pairs,
            'test': test_pairs
        }

        for split_name, pairs in splits.items():
            if not pairs:
                logger.info(f"{split_name}é›†ä¸ºç©ºï¼Œè·³è¿‡")
                continue

            split_image_dir = output_dir / split_name / 'images'
            split_label_dir = output_dir / split_name / 'labels'
            ensure_dir(split_image_dir)
            ensure_dir(split_label_dir)

            # å¤åˆ¶æ–‡ä»¶
            for image_file, label_file in pairs:
                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                dst_image = split_image_dir / image_file.name
                shutil.copy2(image_file, dst_image)

                # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
                dst_label = split_label_dir / label_file.name
                shutil.copy2(label_file, dst_label)

            logger.info(f"{split_name}é›†: {len(pairs)}ä¸ªæ ·æœ¬å·²å¤åˆ¶åˆ° {split_image_dir.parent}")

        logger.info(f"æ‰€æœ‰æ–‡ä»¶å¤åˆ¶å®Œæˆï¼Œè¾“å‡ºç›®å½•: {output_dir}")
        return True

    except Exception as e:
        logger.error(f"æ–‡ä»¶å¤åˆ¶å¤±è´¥: {e}")
        return False

def convert_coco_ultralytics_style(labels_dir: Union[str, Path],
                                   save_dir: Union[str, Path],
                                   use_segments: bool = False,
                                   copy_images: bool = True,
                                   specific_file: Optional[str] = None,
                                   file_pattern: str = "*.json") -> bool:
    """
    Ultralyticsé£æ ¼çš„COCOè½¬æ¢å‡½æ•°
    æ¨¡æ‹Ÿultralytics.data.converter.convert_cocoçš„åŠŸèƒ½

    Args:
        labels_dir: COCO JSONæ ‡æ³¨æ–‡ä»¶æ‰€åœ¨ç›®å½•
        save_dir: è¾“å‡ºç›®å½•
        use_segments: æ˜¯å¦è½¬æ¢åˆ†å‰²æ ‡æ³¨ï¼ˆæš‚ä¸æ”¯æŒï¼‰
        copy_images: æ˜¯å¦å¤åˆ¶å›¾åƒæ–‡ä»¶
        specific_file: æŒ‡å®šè½¬æ¢çš„æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤"*.json"ï¼‰

    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    try:
        labels_dir = Path(labels_dir)
        save_dir = Path(save_dir)

        logger.info(f"å¼€å§‹COCOåˆ°YOLOè½¬æ¢...")
        logger.info(f"è¾“å…¥ç›®å½•: {labels_dir}")
        logger.info(f"è¾“å‡ºç›®å½•: {save_dir}")
        logger.info(f"åˆ†å‰²æ¨¡å¼: {use_segments}")

        if use_segments:
            logger.warning("åˆ†å‰²æ¨¡å¼æš‚ä¸æ”¯æŒï¼Œå°†è½¬æ¢ä¸ºè¾¹ç•Œæ¡†æ ¼å¼")

        # æŸ¥æ‰¾COCO JSONæ–‡ä»¶ - æ”¹è¿›çš„æ–‡ä»¶é€‰æ‹©é€»è¾‘
        if specific_file:
            # è½¬æ¢æŒ‡å®šæ–‡ä»¶
            specific_path = labels_dir / specific_file
            if not specific_path.exists():
                logger.error(f"æŒ‡å®šçš„æ–‡ä»¶ä¸å­˜åœ¨: {specific_path}")
                return False
            json_files = [specific_path]
            logger.info(f"è½¬æ¢æŒ‡å®šæ–‡ä»¶: {specific_file}")
        else:
            # ä½¿ç”¨æ¨¡å¼åŒ¹é…æŸ¥æ‰¾æ–‡ä»¶
            json_files = list(labels_dir.glob(file_pattern))
            if not json_files:
                logger.error(f"åœ¨{labels_dir}ä¸­æœªæ‰¾åˆ°åŒ¹é…'{file_pattern}'çš„æ–‡ä»¶")
                return False
            logger.info(f"æ‰¾åˆ°{len(json_files)}ä¸ªåŒ¹é…æ–‡ä»¶: {[f.name for f in json_files]}")

            # å¦‚æœæ‰¾åˆ°å¤šä¸ªæ–‡ä»¶ï¼Œè­¦å‘Šç”¨æˆ·
            if len(json_files) > 1:
                logger.warning("âš ï¸  æ‰¾åˆ°å¤šä¸ªJSONæ–‡ä»¶ï¼Œå°†å…¨éƒ¨è½¬æ¢ã€‚ç±»åˆ«ä¿¡æ¯å°†è¢«æœ€åå¤„ç†çš„æ–‡ä»¶è¦†ç›–ï¼")
                logger.warning("ğŸ’¡ å»ºè®®ä½¿ç”¨ specific_file å‚æ•°æŒ‡å®šå•ä¸ªæ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨ file_pattern è¿‡æ»¤")
                for i, f in enumerate(json_files):
                    logger.info(f"  {i+1}. {f.name}")

                # ç»™ç”¨æˆ·5ç§’æ—¶é—´è€ƒè™‘
                import time
                logger.warning("â° 5ç§’åå¼€å§‹è½¬æ¢ï¼ŒæŒ‰Ctrl+Cå–æ¶ˆ...")
                try:
                    time.sleep(5)
                except KeyboardInterrupt:
                    logger.info("ç”¨æˆ·å–æ¶ˆè½¬æ¢")
                    return False

        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        labels_output_dir = save_dir / "labels"
        images_output_dir = save_dir / "images"
        ensure_dir(labels_output_dir)
        ensure_dir(images_output_dir)

        success_count = 0
        total_images = 0
        all_class_names = []

        # æ”¹è¿›çš„ç±»åˆ«å¤„ç†é€»è¾‘
        if len(json_files) > 1:
            logger.info("ğŸ” å¤šæ–‡ä»¶æ¨¡å¼ï¼šå…ˆæ£€æŸ¥ç±»åˆ«ä¸€è‡´æ€§...")

            # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çš„ç±»åˆ«æ˜¯å¦ä¸€è‡´
            for i, json_file in enumerate(json_files):
                with open(json_file, 'r', encoding='utf-8') as f:
                    coco_data = json.load(f)
                categories = coco_data.get('categories', [])
                class_names = [cat['name'] for cat in categories]

                if i == 0:
                    all_class_names = class_names
                    logger.info(f"åŸºå‡†ç±»åˆ« ({json_file.name}): {class_names}")
                else:
                    if class_names != all_class_names:
                        logger.error(f"âŒ ç±»åˆ«ä¸ä¸€è‡´ï¼")
                        logger.error(f"åŸºå‡†æ–‡ä»¶ç±»åˆ«: {all_class_names}")
                        logger.error(f"å½“å‰æ–‡ä»¶ ({json_file.name}) ç±»åˆ«: {class_names}")
                        logger.error("ğŸ’¡ å»ºè®®ï¼šä½¿ç”¨ specific_file å‚æ•°å•ç‹¬è½¬æ¢ï¼Œæˆ–ç¡®ä¿æ‰€æœ‰æ–‡ä»¶ç±»åˆ«ä¸€è‡´")
                        return False
                    logger.info(f"âœ… ç±»åˆ«ä¸€è‡´ ({json_file.name})")

            logger.info("âœ… æ‰€æœ‰æ–‡ä»¶ç±»åˆ«ä¸€è‡´ï¼Œç»§ç»­è½¬æ¢...")

        for json_file in json_files:
            logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {json_file.name}")

            # åŠ è½½COCOæ•°æ®
            with open(json_file, 'r', encoding='utf-8') as f:
                coco_data = json.load(f)

            # æå–ç±»åˆ«ä¿¡æ¯
            categories = coco_data.get('categories', [])
            class_names = [cat['name'] for cat in categories]

            # åªåœ¨ç¬¬ä¸€ä¸ªæ–‡ä»¶æˆ–å•æ–‡ä»¶æ—¶ä¿å­˜ç±»åˆ«ä¿¡æ¯
            if json_files.index(json_file) == 0:
                classes_file = save_dir / "classes.txt"
                with open(classes_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(class_names))
                logger.info(f"ğŸ’¾ ä¿å­˜ç±»åˆ«ä¿¡æ¯åˆ°: {classes_file}")
                logger.info(f"ğŸ·ï¸  ç±»åˆ«åˆ—è¡¨: {class_names}")
            else:
                logger.info(f"â­ï¸  è·³è¿‡ç±»åˆ«ä¿å­˜ (å·²å­˜åœ¨)")

            # åˆ›å»ºè½¬æ¢å™¨
            converter = COCOToYOLOConverter()
            converter.set_classes(class_names)

            # åˆ›å»ºå›¾åƒIDåˆ°æ–‡ä»¶åçš„æ˜ å°„
            images = coco_data.get('images', [])
            image_id_to_info = {img['id']: img for img in images}
            total_images += len(images)

            # æŒ‰å›¾åƒåˆ†ç»„æ ‡æ³¨
            annotations = coco_data.get('annotations', [])
            image_annotations = {}
            for ann in annotations:
                image_id = ann['image_id']
                if image_id not in image_annotations:
                    image_annotations[image_id] = []
                image_annotations[image_id].append(ann)

            # è½¬æ¢æ¯ä¸ªå›¾åƒçš„æ ‡æ³¨
            for image_id, anns in image_annotations.items():
                if image_id not in image_id_to_info:
                    continue

                image_info = image_id_to_info[image_id]
                image_width = image_info['width']
                image_height = image_info['height']
                image_filename = Path(image_info['file_name']).stem

                # è½¬æ¢æ ‡æ³¨
                yolo_lines = []
                for ann in anns:
                    if use_segments and 'segmentation' in ann:
                        # åˆ†å‰²æ ‡æ³¨å¤„ç†ï¼ˆæš‚æ—¶è·³è¿‡ï¼‰
                        logger.warning(f"è·³è¿‡åˆ†å‰²æ ‡æ³¨: {image_filename}")
                        continue

                    bbox = ann['bbox']  # [x, y, width, height]
                    category_id = ann['category_id']

                    # è½¬æ¢ä¸ºYOLOæ ¼å¼
                    yolo_bbox = converter._coco_bbox_to_yolo(bbox, image_width, image_height)
                    yolo_class_id = converter._coco_category_to_yolo_class(category_id, categories)

                    yolo_line = f"{yolo_class_id} {' '.join(map(str, yolo_bbox))}"
                    yolo_lines.append(yolo_line)

                # ä¿å­˜YOLOæ ‡æ³¨æ–‡ä»¶
                output_file = labels_output_dir / f"{image_filename}.txt"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(yolo_lines))

                # å¤åˆ¶å›¾åƒæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if copy_images:
                    # æ™ºèƒ½è·¯å¾„æŸ¥æ‰¾åŸå§‹å›¾åƒæ–‡ä»¶
                    image_filename = image_info['file_name']
                    search_paths = [
                        labels_dir.parent / "images" / image_filename,  # raw/images/
                        labels_dir / image_filename,                    # original_annotations/
                        labels_dir.parent / image_filename,             # raw/
                        labels_dir.parent.parent / "images" / image_filename,  # data/images/
                        Path.cwd() / "images" / image_filename,         # å½“å‰ç›®å½•/images/
                        Path.cwd() / image_filename,                    # å½“å‰ç›®å½•
                    ]

                    original_image_path = None
                    for path in search_paths:
                        if path.exists():
                            original_image_path = path
                            break

                    if original_image_path:
                        dst_image_path = images_output_dir / image_filename
                        shutil.copy2(original_image_path, dst_image_path)
                        logger.debug(f"å¤åˆ¶å›¾ç‰‡: {original_image_path.name} -> {dst_image_path.name}")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {image_filename}")
                        logger.debug(f"å·²æœç´¢è·¯å¾„: {len(search_paths)}ä¸ªä½ç½®")

                success_count += 1

        logger.info(f"è½¬æ¢å®Œæˆ!")
        logger.info(f"æˆåŠŸè½¬æ¢: {success_count}/{total_images} ä¸ªå›¾åƒ")
        logger.info(f"è¾“å‡ºç›®å½•: {save_dir}")
        logger.info(f"æ ‡ç­¾ç›®å½•: {labels_output_dir}")
        logger.info(f"å›¾åƒç›®å½•: {images_output_dir}")

        return True

    except Exception as e:
        logger.error(f"COCOè½¬æ¢å¤±è´¥: {e}")
        return False

def convert_single_coco_file(coco_file_path: Union[str, Path],
                            save_dir: Union[str, Path],
                            use_segments: bool = False,
                            copy_images: bool = True) -> bool:
    """
    è½¬æ¢å•ä¸ªCOCOæ–‡ä»¶åˆ°YOLOæ ¼å¼ - æ›´ç®€å•ç›´æ¥çš„æ¥å£

    Args:
        coco_file_path: COCO JSONæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        save_dir: è¾“å‡ºç›®å½•
        use_segments: æ˜¯å¦è½¬æ¢åˆ†å‰²æ ‡æ³¨ï¼ˆæš‚ä¸æ”¯æŒï¼‰
        copy_images: æ˜¯å¦å¤åˆ¶å›¾åƒæ–‡ä»¶

    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    coco_file_path = Path(coco_file_path)

    if not coco_file_path.exists():
        logger.error(f"COCOæ–‡ä»¶ä¸å­˜åœ¨: {coco_file_path}")
        return False

    if not coco_file_path.suffix.lower() == '.json':
        logger.error(f"æ–‡ä»¶ä¸æ˜¯JSONæ ¼å¼: {coco_file_path}")
        return False

    # ä½¿ç”¨æ–‡ä»¶æ‰€åœ¨ç›®å½•ä½œä¸ºlabels_dirï¼ŒæŒ‡å®šå…·ä½“æ–‡ä»¶å
    labels_dir = coco_file_path.parent
    specific_file = coco_file_path.name

    logger.info(f"ğŸ¯ è½¬æ¢å•ä¸ªæ–‡ä»¶: {coco_file_path}")

    return convert_coco_ultralytics_style(
        labels_dir=labels_dir,
        save_dir=save_dir,
        use_segments=use_segments,
        copy_images=copy_images,
        specific_file=specific_file
    )

def validate_annotations(label_dir: Union[str, Path],
                        image_dir: Optional[Union[str, Path]] = None,
                        class_count: Optional[int] = None) -> Dict:
    """
    éªŒè¯YOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶

    Args:
        label_dir: æ ‡ç­¾ç›®å½•
        image_dir: å›¾åƒç›®å½•ï¼ˆå¯é€‰ï¼‰
        class_count: ç±»åˆ«æ•°é‡ï¼ˆå¯é€‰ï¼‰

    Returns:
        Dict: éªŒè¯ç»“æœç»Ÿè®¡
    """
    try:
        label_dir = Path(label_dir)

        stats = {
            'total_files': 0,
            'valid_files': 0,
            'invalid_files': 0,
            'empty_files': 0,
            'errors': [],
            'class_distribution': {},
            'bbox_stats': {
                'total_boxes': 0,
                'invalid_boxes': 0
            }
        }

        label_files = list(label_dir.glob("*.txt"))
        stats['total_files'] = len(label_files)

        for label_file in label_files:
            try:
                with open(label_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()

                if not lines or all(not line.strip() for line in lines):
                    stats['empty_files'] += 1
                    continue

                file_valid = True
                for line_num, line in enumerate(lines, 1):
                    line = line.strip()
                    if not line:
                        continue

                    parts = line.split()
                    if len(parts) != 5:
                        stats['errors'].append(f"{label_file.name}:{line_num} - æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º5ä¸ªå€¼")
                        file_valid = False
                        continue

                    try:
                        class_id = int(parts[0])
                        x, y, w, h = map(float, parts[1:])

                        # æ£€æŸ¥ç±»åˆ«ID
                        if class_count is not None and (class_id < 0 or class_id >= class_count):
                            stats['errors'].append(f"{label_file.name}:{line_num} - ç±»åˆ«IDè¶…å‡ºèŒƒå›´: {class_id}")
                            file_valid = False

                        # æ£€æŸ¥åæ ‡èŒƒå›´
                        if not (0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                            stats['errors'].append(f"{label_file.name}:{line_num} - åæ ‡è¶…å‡ºèŒƒå›´ [0,1]")
                            stats['bbox_stats']['invalid_boxes'] += 1
                            file_valid = False

                        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
                        if class_id not in stats['class_distribution']:
                            stats['class_distribution'][class_id] = 0
                        stats['class_distribution'][class_id] += 1
                        stats['bbox_stats']['total_boxes'] += 1

                    except ValueError:
                        stats['errors'].append(f"{label_file.name}:{line_num} - æ•°å€¼æ ¼å¼é”™è¯¯")
                        file_valid = False

                if file_valid:
                    stats['valid_files'] += 1
                else:
                    stats['invalid_files'] += 1

            except Exception as e:
                stats['errors'].append(f"{label_file.name} - è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                stats['invalid_files'] += 1

        # æ£€æŸ¥å›¾åƒ-æ ‡ç­¾å¯¹åº”å…³ç³»
        if image_dir:
            image_dir = Path(image_dir)
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']

            # æ‰¾åˆ°æ‰€æœ‰å›¾åƒæ–‡ä»¶
            image_files = set()
            for ext in image_extensions:
                image_files.update(f.stem for f in image_dir.glob(f"*{ext}"))
                image_files.update(f.stem for f in image_dir.glob(f"*{ext.upper()}"))

            # æ‰¾åˆ°æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
            label_files = set(f.stem for f in label_dir.glob("*.txt"))

            # æ£€æŸ¥ä¸åŒ¹é…çš„æ–‡ä»¶
            images_without_labels = image_files - label_files
            labels_without_images = label_files - image_files

            if images_without_labels:
                stats['errors'].append(f"ç¼ºå°‘æ ‡ç­¾çš„å›¾åƒ: {len(images_without_labels)}ä¸ª")

            if labels_without_images:
                stats['errors'].append(f"ç¼ºå°‘å›¾åƒçš„æ ‡ç­¾: {len(labels_without_images)}ä¸ª")

        logger.info(f"æ ‡æ³¨éªŒè¯å®Œæˆ: {stats['valid_files']}/{stats['total_files']} æ–‡ä»¶æœ‰æ•ˆ")
        return stats

    except Exception as e:
        logger.error(f"æ ‡æ³¨éªŒè¯å¤±è´¥: {e}")
        return {'error': str(e)}

# ç›´æ¥è¿è¡Œçš„ç¤ºä¾‹
if __name__ == "__main__":
    """
    ç›´æ¥è¿è¡ŒCOCOè½¬æ¢çš„ç¤ºä¾‹
    å¯ä»¥ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡ŒCOCOåˆ°YOLOçš„è½¬æ¢

    ä½¿ç”¨æ–¹æ³•:
    python data_converter.py              # äº¤äº’å¼è¿è¡Œ
    python data_converter.py --auto       # è‡ªåŠ¨è¿è¡Œï¼Œä¸éœ€è¦ç¡®è®¤
    python data_converter.py -a           # è‡ªåŠ¨è¿è¡Œçš„ç®€å†™
    """
    import sys
    import argparse
    from pathlib import Path

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="COCOåˆ°YOLOè½¬æ¢å·¥å…·")
    parser.add_argument('--auto', '-a', action='store_true', help='è‡ªåŠ¨è¿è¡Œï¼Œä¸éœ€è¦ç¡®è®¤')
    parser.add_argument('--input', '-i', type=str, help='è¾“å…¥ç›®å½•è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºç›®å½•è·¯å¾„')
    args = parser.parse_args()

    # è®¾ç½®é»˜è®¤è·¯å¾„
    project_root = Path(__file__).parent.parent.parent
    default_input = Path(args.input) if args.input else project_root / "yoloserver" / "data" / "raw" / "original_annotations"
    default_output = Path(args.output) if args.output else project_root / "yoloserver" / "data" / "raw" / "yolo_converted"

    print("=" * 60)
    print("ğŸš€ BTD COCOè½¬æ¢å·¥å…·")
    print("=" * 60)

    # æ£€æŸ¥é»˜è®¤è¾“å…¥ç›®å½•
    if default_input.exists():
        json_files = list(default_input.glob("*.json"))
        if json_files:
            print(f"âœ… æ‰¾åˆ°è¾“å…¥ç›®å½•: {default_input}")
            print(f"ğŸ“ å‘ç° {len(json_files)} ä¸ªJSONæ–‡ä»¶:")
            for f in json_files:
                print(f"   - {f.name}")

            print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {default_output}")

            # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦éœ€è¦ç¡®è®¤
            if args.auto:
                print("\nğŸ”„ è‡ªåŠ¨æ¨¡å¼ï¼Œå¼€å§‹è½¬æ¢...")
                should_convert = True
            else:
                # æ£€æŸ¥æ˜¯å¦åœ¨äº¤äº’å¼ç¯å¢ƒä¸­
                try:
                    # å°è¯•è·å–ç”¨æˆ·è¾“å…¥
                    response = input("\nğŸ¤” æ˜¯å¦å¼€å§‹è½¬æ¢ï¼Ÿ(y/N): ").strip().lower()
                    should_convert = (response == 'y')
                except (EOFError, KeyboardInterrupt):
                    # å¦‚æœæ— æ³•è·å–è¾“å…¥ï¼ˆå¦‚åœ¨VS Codeä¸­è¿è¡Œï¼‰ï¼Œè‡ªåŠ¨å¼€å§‹è½¬æ¢
                    print("\nğŸ”„ æ£€æµ‹åˆ°éäº¤äº’å¼ç¯å¢ƒï¼Œè‡ªåŠ¨å¼€å§‹è½¬æ¢...")
                    should_convert = True

            if should_convert:
                print("\nğŸ”„ å¼€å§‹è½¬æ¢...")
                success = convert_coco_ultralytics_style(
                    labels_dir=str(default_input),
                    save_dir=str(default_output),
                    use_segments=False,
                    copy_images=True
                )

                if success:
                    print("âœ… è½¬æ¢å®Œæˆï¼")
                    print(f"ğŸ“ è¾“å‡ºç›®å½•: {default_output}")
                else:
                    print("âŒ è½¬æ¢å¤±è´¥ï¼")
                    sys.exit(1)
            else:
                print("å–æ¶ˆè½¬æ¢")
        else:
            print(f"âŒ è¾“å…¥ç›®å½•ä¸­æ²¡æœ‰JSONæ–‡ä»¶: {default_input}")
            print("ğŸ’¡ è¯·å°†COCO JSONæ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•")
    else:
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {default_input}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œé¡¹ç›®åˆå§‹åŒ–: python main.py init")

    print("\nğŸ’¡ å…¶ä»–ä½¿ç”¨æ–¹æ³•:")
    print("1. python yoloserver/scripts/data_processing.py process --input <ç›®å½•> --format auto")
    print("2. python main.py data convert --input <è¾“å…¥> --output <è¾“å‡º> --input-format coco")
