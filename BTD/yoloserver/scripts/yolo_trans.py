# -*- coding: utf-8 -*-
# -*- coding:utf-8 -*-
# @FileName  :yolo_trans.py
# @Time      :2025/6/24 16:00:00
# @Author    :BTD Team
# @Project   :BTD
# @Function  :YOLOæ•°æ®è½¬æ¢é¡¶å±‚è„šæœ¬ï¼Œæä¾›å®Œæ•´çš„æ•°æ®è½¬æ¢ã€åˆ†å‰²ã€data.yamlç”Ÿæˆçš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆ

import sys
import shutil
from pathlib import Path
from typing import List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from yoloserver.utils.logger import setup_logger, get_logger
from yoloserver.utils.performance_utils import time_it, PerformanceProfiler
from yoloserver.utils.path_utils import get_data_paths, get_config_paths, ensure_dir
from yoloserver.utils.file_utils import write_yaml
from yoloserver.utils.data_converter import (
    convert_coco_ultralytics_style,
    convert_pascal_to_yolo,
    split_dataset,
    validate_annotations
)

logger = get_logger(__name__)


class YOLODataTransformer:
    """YOLOæ•°æ®è½¬æ¢å™¨"""
    
    def __init__(self, clean_previous: bool = True):
        """
        åˆå§‹åŒ–YOLOæ•°æ®è½¬æ¢å™¨
        
        Args:
            clean_previous: æ˜¯å¦æ¸…ç†ä¹‹å‰çš„æ•°æ®
        """
        self.data_paths = get_data_paths()
        self.config_paths = get_config_paths()
        self.clean_previous = clean_previous
        self.profiler = PerformanceProfiler(logger)
        self.class_names = []
        
        # è®¾ç½®æ—¥å¿—
        setup_logger("yolo_trans", console_output=True, file_output=True)
        
    def clean_previous_data(self) -> None:
        """æ¸…ç†ä¹‹å‰çš„åˆ’åˆ†ç›®å½•å’Œdata.yamlæ–‡ä»¶"""
        logger.info("å¼€å§‹æ¸…ç†ä¹‹å‰çš„æ•°æ®...")

        # æ¸…ç†processedå’Œtrain/val/testç›®å½•
        dirs_to_clean = [
            self.data_paths['processed_data'],
            self.data_paths['train_images'],
            self.data_paths['train_labels'],
            self.data_paths['val_images'],
            self.data_paths['val_labels'],
            self.data_paths['test_images'],
            self.data_paths['test_labels']
        ]

        for dir_path in dirs_to_clean:
            if dir_path.exists():
                shutil.rmtree(dir_path)
                logger.info(f"å·²æ¸…ç†ç›®å½•: {dir_path}")

        # æ¸…ç†æ··ä¹±çš„è½¬æ¢è¾“å‡ºç›®å½•
        messy_dirs = [
            self.data_paths['raw_data'] / 'coco_converted',
            self.data_paths['raw_data'] / 'yolo_converted_cli'
        ]

        for dir_path in messy_dirs:
            if dir_path.exists():
                shutil.rmtree(dir_path)
                logger.info(f"å·²æ¸…ç†æ··ä¹±çš„è½¬æ¢ç›®å½•: {dir_path}")

        # æ¸…ç†data.yamlæ–‡ä»¶
        data_yaml_path = self.config_paths['configs_dir'] / 'data.yaml'
        if data_yaml_path.exists():
            data_yaml_path.unlink()
            logger.info(f"å·²æ¸…ç†é…ç½®æ–‡ä»¶: {data_yaml_path}")

        logger.info("æ•°æ®æ¸…ç†å®Œæˆ")
    
    @time_it(iterations=1, name="æ•°æ®è½¬æ¢", logger_instance=logger)
    def convert_annotations(self, input_dir: str, annotation_format: str = "auto", 
                          class_names: Optional[List[str]] = None) -> bool:
        """
        è½¬æ¢æ ‡æ³¨æ ¼å¼
        
        Args:
            input_dir: è¾“å…¥ç›®å½•
            annotation_format: æ ‡æ³¨æ ¼å¼ (auto, coco, pascal, yolo)
            class_names: ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆPascal VOCéœ€è¦ï¼‰
            
        Returns:
            bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        logger.info(f"å¼€å§‹è½¬æ¢æ ‡æ³¨æ ¼å¼: {annotation_format}")
        self.profiler.start_timer("æ ‡æ³¨è½¬æ¢")
        
        try:
            input_dir = Path(input_dir)
            output_dir = self.data_paths['yolo_labels']
            ensure_dir(output_dir)
            
            # è‡ªåŠ¨æ£€æµ‹æ ‡æ³¨æ ¼å¼
            if annotation_format == "auto":
                if list(input_dir.glob("*.json")):
                    annotation_format = "coco"
                    logger.info("è‡ªåŠ¨æ£€æµ‹åˆ°COCOæ ¼å¼æ ‡æ³¨")
                elif list(input_dir.glob("*.xml")):
                    annotation_format = "pascal"
                    logger.info("è‡ªåŠ¨æ£€æµ‹åˆ°Pascal VOCæ ¼å¼æ ‡æ³¨")
                elif list(input_dir.glob("*.txt")):
                    annotation_format = "yolo"
                    logger.info("è‡ªåŠ¨æ£€æµ‹åˆ°YOLOæ ¼å¼æ ‡æ³¨")
                else:
                    logger.error("æ— æ³•è‡ªåŠ¨æ£€æµ‹æ ‡æ³¨æ ¼å¼")
                    return False
            
            # æ‰§è¡Œè½¬æ¢
            if annotation_format == "coco":
                success = convert_coco_ultralytics_style(
                    labels_dir=str(input_dir),
                    save_dir=str(output_dir.parent / "coco_converted"),
                    use_segments=False,
                    copy_images=False  # ä¸å¤åˆ¶å›¾åƒï¼Œé¿å…é‡å¤
                )
                
                if success:
                    # æå–ç±»åˆ«ä¿¡æ¯
                    classes_file = output_dir.parent / "coco_converted" / "classes.txt"
                    if classes_file.exists():
                        with open(classes_file, 'r', encoding='utf-8') as f:
                            self.class_names = [line.strip() for line in f.readlines() if line.strip()]
                    
                    # ç§»åŠ¨æ ‡ç­¾æ–‡ä»¶åˆ°æŒ‡å®šä½ç½®
                    source_labels = output_dir.parent / "coco_converted" / "labels"
                    if source_labels.exists():
                        for txt_file in source_labels.glob("*.txt"):
                            shutil.move(str(txt_file), str(output_dir / txt_file.name))
                        logger.info(f"å·²ç§»åŠ¨æ ‡ç­¾æ–‡ä»¶åˆ°: {output_dir}")
                
            elif annotation_format == "pascal":
                if not class_names:
                    logger.error("Pascal VOCè½¬æ¢éœ€è¦æä¾›ç±»åˆ«åç§°åˆ—è¡¨")
                    return False
                
                self.class_names = class_names
                success = convert_pascal_to_yolo(
                    xml_dir=input_dir,
                    output_dir=output_dir,
                    class_names=class_names,
                    image_dir=self.data_paths['raw_images']
                )
                
            elif annotation_format == "yolo":
                # å·²ç»æ˜¯YOLOæ ¼å¼ï¼Œç›´æ¥å¤åˆ¶
                txt_files = list(input_dir.glob("*.txt"))
                for txt_file in txt_files:
                    shutil.copy2(txt_file, output_dir / txt_file.name)
                logger.info(f"å¤åˆ¶äº†{len(txt_files)}ä¸ªYOLOæ ‡æ³¨æ–‡ä»¶")
                
                # éœ€è¦æ‰‹åŠ¨æŒ‡å®šç±»åˆ«åç§°
                if class_names:
                    self.class_names = class_names
                else:
                    logger.warning("YOLOæ ¼å¼è½¬æ¢å»ºè®®æä¾›ç±»åˆ«åç§°åˆ—è¡¨")
                    self.class_names = [f"class_{i}" for i in range(10)]  # é»˜è®¤10ä¸ªç±»åˆ«
                
                success = True
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ ‡æ³¨æ ¼å¼: {annotation_format}")
                return False
            
            self.profiler.end_timer("æ ‡æ³¨è½¬æ¢")
            
            if success:
                logger.info(f"æ ‡æ³¨è½¬æ¢å®Œæˆï¼Œç±»åˆ«æ•°é‡: {len(self.class_names)}")
                logger.info(f"ç±»åˆ«åˆ—è¡¨: {self.class_names}")
            
            return success
            
        except Exception as e:
            logger.error(f"æ ‡æ³¨è½¬æ¢å¤±è´¥: {e}")
            return False
    
    @time_it(iterations=1, name="æ•´ç†æœ‰æ•ˆæ•°æ®", logger_instance=logger)
    def organize_valid_data(self) -> bool:
        """æ•´ç†æœ‰æ•ˆæ•°æ®åˆ°processedç›®å½•"""
        logger.info("å¼€å§‹æ•´ç†æœ‰æ•ˆæ•°æ®...")
        self.profiler.start_timer("æ•´ç†æœ‰æ•ˆæ•°æ®")

        try:
            from yoloserver.utils.data_converter import organize_valid_pairs
            success = organize_valid_pairs(
                image_dir=self.data_paths['raw_images'],
                label_dir=self.data_paths['yolo_labels'],
                output_dir=self.data_paths['processed_data']
            )

            self.profiler.end_timer("æ•´ç†æœ‰æ•ˆæ•°æ®")

            if success:
                logger.info("æœ‰æ•ˆæ•°æ®æ•´ç†å®Œæˆ")
            else:
                logger.error("æœ‰æ•ˆæ•°æ®æ•´ç†å¤±è´¥")

            return success

        except Exception as e:
            logger.error(f"æœ‰æ•ˆæ•°æ®æ•´ç†å¤±è´¥: {e}")
            return False

    @time_it(iterations=1, name="æ•°æ®é›†åˆ†å‰²", logger_instance=logger)
    def split_dataset_data(self, train_ratio: float = 0.7, val_ratio: float = 0.2,
                          test_ratio: float = 0.1, seed: int = 42) -> bool:
        """
        åˆ†å‰²æ•°æ®é›†

        Args:
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
            seed: éšæœºç§å­

        Returns:
            bool: åˆ†å‰²æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹åˆ†å‰²æ•°æ®é›†...")
        self.profiler.start_timer("æ•°æ®é›†åˆ†å‰²")

        try:
            success = split_dataset(
                image_dir=self.data_paths['processed_images'],
                label_dir=self.data_paths['processed_labels'],
                output_dir=self.data_paths['data_root'],
                train_ratio=train_ratio,
                val_ratio=val_ratio,
                test_ratio=test_ratio,
                seed=seed
            )
            
            self.profiler.end_timer("æ•°æ®é›†åˆ†å‰²")
            
            if success:
                logger.info("æ•°æ®é›†åˆ†å‰²å®Œæˆ")
                
                # ç»Ÿè®¡åˆ†å‰²ç»“æœ
                train_count = len(list(self.data_paths['train_images'].glob("*")))
                val_count = len(list(self.data_paths['val_images'].glob("*")))
                test_count = len(list(self.data_paths['test_images'].glob("*")))
                
                logger.info(f"è®­ç»ƒé›†: {train_count} ä¸ªæ ·æœ¬")
                logger.info(f"éªŒè¯é›†: {val_count} ä¸ªæ ·æœ¬")
                logger.info(f"æµ‹è¯•é›†: {test_count} ä¸ªæ ·æœ¬")
            
            return success
            
        except Exception as e:
            logger.error(f"æ•°æ®é›†åˆ†å‰²å¤±è´¥: {e}")
            return False
    
    @time_it(iterations=1, name="ç”Ÿæˆdata.yaml", logger_instance=logger)
    def generate_data_yaml(self) -> bool:
        """
        ç”Ÿæˆdata.yamlé…ç½®æ–‡ä»¶
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹ç”Ÿæˆdata.yamlé…ç½®æ–‡ä»¶...")
        self.profiler.start_timer("ç”Ÿæˆdata.yaml")
        
        try:
            # æ„å»ºdata.yamlå†…å®¹ - ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿è®­ç»ƒè„šæœ¬èƒ½æ­£ç¡®æ‰¾åˆ°æ•°æ®
            # è·å–æ•°æ®ç›®å½•çš„ç»å¯¹è·¯å¾„
            data_dir_abs = self.data_paths['data_root'].resolve()

            data_config = {
                'path': str(data_dir_abs),  # ä½¿ç”¨ç»å¯¹è·¯å¾„
                'train': 'train/images',
                'val': 'val/images',
                'test': 'test/images',
                'nc': len(self.class_names),
                'names': self.class_names
            }
            
            # ä¿å­˜data.yamlæ–‡ä»¶
            data_yaml_path = self.config_paths['configs_dir'] / 'data.yaml'
            ensure_dir(data_yaml_path.parent)
            
            success = write_yaml(data_config, data_yaml_path)
            
            self.profiler.end_timer("ç”Ÿæˆdata.yaml")
            
            if success:
                logger.info(f"data.yamlé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {data_yaml_path}")
                logger.info("é…ç½®å†…å®¹:")
                for key, value in data_config.items():
                    logger.info(f"  {key}: {value}")
            
            return success
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆdata.yamlå¤±è´¥: {e}")
            return False
    
    def validate_dataset_data(self) -> bool:
        """
        éªŒè¯æ•°æ®é›†
        
        Returns:
            bool: éªŒè¯æ˜¯å¦é€šè¿‡
        """
        logger.info("å¼€å§‹éªŒè¯æ•°æ®é›†...")
        
        try:
            # éªŒè¯è®­ç»ƒé›†
            train_stats = validate_annotations(
                label_dir=self.data_paths['train_labels'],
                image_dir=self.data_paths['train_images'],
                class_count=len(self.class_names)
            )
            
            # éªŒè¯éªŒè¯é›†
            val_stats = validate_annotations(
                label_dir=self.data_paths['val_labels'],
                image_dir=self.data_paths['val_images'],
                class_count=len(self.class_names)
            )
            
            # éªŒè¯æµ‹è¯•é›†
            test_stats = validate_annotations(
                label_dir=self.data_paths['test_labels'],
                image_dir=self.data_paths['test_images'],
                class_count=len(self.class_names)
            )
            
            # æ±‡æ€»éªŒè¯ç»“æœ
            total_valid = train_stats['valid_files'] + val_stats['valid_files'] + test_stats['valid_files']
            total_files = train_stats['total_files'] + val_stats['total_files'] + test_stats['total_files']
            
            success_rate = total_valid / total_files if total_files > 0 else 0
            
            logger.info(f"æ•°æ®é›†éªŒè¯å®Œæˆ:")
            logger.info(f"  æ€»æ–‡ä»¶æ•°: {total_files}")
            logger.info(f"  æœ‰æ•ˆæ–‡ä»¶æ•°: {total_valid}")
            logger.info(f"  æœ‰æ•ˆç‡: {success_rate:.2%}")
            
            return success_rate >= 0.95  # 95%ä»¥ä¸Šæœ‰æ•ˆç‡è®¤ä¸ºé€šè¿‡
            
        except Exception as e:
            logger.error(f"æ•°æ®é›†éªŒè¯å¤±è´¥: {e}")
            return False

    def run_full_pipeline(self, input_dir: str, annotation_format: str = "auto",
                         class_names: Optional[List[str]] = None,
                         train_ratio: float = 0.7, val_ratio: float = 0.2, test_ratio: float = 0.1,
                         seed: int = 42, validate: bool = True) -> bool:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®è½¬æ¢æµæ°´çº¿

        Args:
            input_dir: è¾“å…¥ç›®å½•
            annotation_format: æ ‡æ³¨æ ¼å¼
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
            seed: éšæœºç§å­
            validate: æ˜¯å¦éªŒè¯æ•°æ®é›†

        Returns:
            bool: æµæ°´çº¿æ˜¯å¦æˆåŠŸ
        """
        print("ğŸš€ å¼€å§‹YOLOæ•°æ®è½¬æ¢æµæ°´çº¿...")
        logger.info("å¼€å§‹YOLOæ•°æ®è½¬æ¢å®Œæ•´æµæ°´çº¿")

        self.profiler.start_timer("å®Œæ•´æµæ°´çº¿")

        try:
            # 1. æ¸…ç†ä¹‹å‰çš„æ•°æ®
            if self.clean_previous:
                self.clean_previous_data()

            # 2. è½¬æ¢æ ‡æ³¨æ ¼å¼
            print("ğŸ“ æ­¥éª¤1: è½¬æ¢æ ‡æ³¨æ ¼å¼...")
            if not self.convert_annotations(input_dir, annotation_format, class_names):
                print("âŒ æ ‡æ³¨è½¬æ¢å¤±è´¥")
                return False
            print("âœ… æ ‡æ³¨è½¬æ¢å®Œæˆ")

            # 3. æ•´ç†æœ‰æ•ˆæ•°æ®
            print("ğŸ“¦ æ­¥éª¤2: æ•´ç†æœ‰æ•ˆæ•°æ®...")
            if not self.organize_valid_data():
                print("âŒ æœ‰æ•ˆæ•°æ®æ•´ç†å¤±è´¥")
                return False
            print("âœ… æœ‰æ•ˆæ•°æ®æ•´ç†å®Œæˆ")

            # 4. åˆ†å‰²æ•°æ®é›†
            print("ğŸ“‚ æ­¥éª¤3: åˆ†å‰²æ•°æ®é›†...")
            if not self.split_dataset_data(train_ratio, val_ratio, test_ratio, seed):
                print("âŒ æ•°æ®é›†åˆ†å‰²å¤±è´¥")
                return False
            print("âœ… æ•°æ®é›†åˆ†å‰²å®Œæˆ")

            # 5. ç”Ÿæˆdata.yaml
            print("âš™ï¸ æ­¥éª¤4: ç”Ÿæˆdata.yamlé…ç½®æ–‡ä»¶...")
            if not self.generate_data_yaml():
                print("âŒ data.yamlç”Ÿæˆå¤±è´¥")
                return False
            print("âœ… data.yamlç”Ÿæˆå®Œæˆ")

            # 6. éªŒè¯æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
            if validate:
                print("ğŸ” æ­¥éª¤5: éªŒè¯æ•°æ®é›†...")
                if not self.validate_dataset_data():
                    print("âš ï¸ æ•°æ®é›†éªŒè¯æœªå®Œå…¨é€šè¿‡ï¼Œä½†æµæ°´çº¿ç»§ç»­")
                else:
                    print("âœ… æ•°æ®é›†éªŒè¯é€šè¿‡")

            self.profiler.end_timer("å®Œæ•´æµæ°´çº¿")

            print("\n" + "="*50)
            print("ğŸ‰ YOLOæ•°æ®è½¬æ¢æµæ°´çº¿å®Œæˆï¼")
            print("="*50)

            # è¾“å‡ºä¸‹ä¸€æ­¥å»ºè®®
            data_yaml_path = self.config_paths['configs_dir'] / 'data.yaml'
            print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
            print(f"1. æ£€æŸ¥ç”Ÿæˆçš„é…ç½®æ–‡ä»¶: {data_yaml_path}")
            print("2. å¼€å§‹è®­ç»ƒæ¨¡å‹:")
            print("   python BTD/main.py train")
            print("3. æˆ–æŸ¥çœ‹è½¬æ¢ç»“æœ:")
            print(f"   - è®­ç»ƒé›†: {self.data_paths['train_images']}")
            print(f"   - éªŒè¯é›†: {self.data_paths['val_images']}")
            print(f"   - æµ‹è¯•é›†: {self.data_paths['test_images']}")

            return True

        except Exception as e:
            logger.error(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            return False

    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 0.001:
            return f"{seconds * 1000:.1f} æ¯«ç§’"
        elif seconds < 60:
            return f"{seconds:.2f} ç§’"
        else:
            minutes = int(seconds // 60)
            remaining_seconds = seconds % 60
            return f"{minutes} åˆ† {remaining_seconds:.1f} ç§’"


def main():
    """ä¸»å‡½æ•° - ç®€åŒ–ç‰ˆï¼Œç›´æ¥è¿è¡Œå³å¯"""
    print("=" * 60)
    print("ğŸš€ YOLOæ•°æ®è½¬æ¢ä¸€ç«™å¼å·¥å…·")
    print("=" * 60)

    # è®¾ç½®é»˜è®¤è·¯å¾„
    project_root = Path(__file__).parent.parent.parent
    default_input = project_root / "yoloserver" / "data" / "raw" / "original_annotations"

    print(f"ğŸ“ è¾“å…¥ç›®å½•: {default_input}")

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not default_input.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {default_input}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python main.py init")
        return 1

    # åˆ›å»ºè½¬æ¢å™¨å¹¶è¿è¡Œ
    transformer = YOLODataTransformer(clean_previous=True)

    success = transformer.run_full_pipeline(
        input_dir=str(default_input),
        annotation_format="auto",
        class_names=None,
        train_ratio=0.7,
        val_ratio=0.2,
        test_ratio=0.1,
        seed=42,
        validate=True
    )

    if success:
        print("ğŸ‰ æ•°æ®è½¬æ¢æµæ°´çº¿æ‰§è¡ŒæˆåŠŸï¼")
        return 0
    else:
        print("âŒ æ•°æ®è½¬æ¢æµæ°´çº¿æ‰§è¡Œå¤±è´¥ï¼")
        return 1


def run_with_params(input_dir: str, annotation_format: str = "auto",
                   class_names: Optional[List[str]] = None,
                   train_ratio: float = 0.7, val_ratio: float = 0.2, test_ratio: float = 0.1,
                   seed: int = 42, validate: bool = True, clean_previous: bool = True) -> bool:
    """
    ä¾›å…¶ä»–ä»£ç è°ƒç”¨çš„å‡½æ•°æ¥å£

    Args:
        input_dir: è¾“å…¥æ ‡æ³¨æ–‡ä»¶ç›®å½•
        annotation_format: æ ‡æ³¨æ ¼å¼ (auto, coco, pascal, yolo)
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
        seed: éšæœºç§å­
        validate: æ˜¯å¦éªŒè¯æ•°æ®é›†
        clean_previous: æ˜¯å¦æ¸…ç†ä¹‹å‰çš„æ•°æ®

    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    transformer = YOLODataTransformer(clean_previous=clean_previous)

    return transformer.run_full_pipeline(
        input_dir=input_dir,
        annotation_format=annotation_format,
        class_names=class_names,
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        test_ratio=test_ratio,
        seed=seed,
        validate=validate
    )


if __name__ == "__main__":
    main()
