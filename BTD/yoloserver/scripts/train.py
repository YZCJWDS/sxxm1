#!/usr/bin/env python3
"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
æä¾›YOLOæ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
é›†æˆäº†é…ç½®ç®¡ç†ã€ç³»ç»Ÿä¿¡æ¯è®°å½•ã€æ•°æ®é›†ä¿¡æ¯è®°å½•ã€è®­ç»ƒåå¤„ç†ç­‰å®Œæ•´åŠŸèƒ½
"""

import argparse
import sys
import logging
import shutil
import json
import time
import platform
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from yoloserver.utils.logger import setup_logger, get_logger, TimerLogger
from yoloserver.utils.path_utils import get_project_root, get_config_paths, get_model_paths
from yoloserver.utils.file_utils import read_yaml, write_yaml
from yoloserver.utils.performance_utils import time_it

logger = get_logger(__name__)

# å°è¯•å¯¼å…¥psutilç”¨äºç³»ç»Ÿä¿¡æ¯è·å–
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    logger.warning("psutilæœªå®‰è£…ï¼Œç³»ç»Ÿä¿¡æ¯è®°å½•åŠŸèƒ½å—é™ã€‚å®‰è£…å‘½ä»¤: pip install psutil")

# ==================== é…ç½®ç®¡ç†åŠŸèƒ½ ====================

def load_config(config_type='train'):
    """
    åŠ è½½é…ç½®æ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶ååŠ è½½

    Args:
        config_type: é…ç½®æ–‡ä»¶ç±»å‹ ('train', 'val', 'infer')

    Returns:
        dict: é…ç½®æ–‡ä»¶å†…å®¹
    """
    try:
        config_paths = get_config_paths()
        config_path = config_paths.get('configs_dir', Path('configs')) / f'{config_type}.yaml'

        if config_path.exists():
            config = read_yaml(config_path)
            logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            return config
        else:
            logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return get_default_config(config_type)
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return get_default_config(config_type)

def get_default_config(config_type='train'):
    """è·å–é»˜è®¤é…ç½®"""
    if config_type == 'train':
        return {
            'data': 'data.yaml',
            'epochs': 100,
            'batch': 16,
            'imgsz': 640,
            'device': 'cpu',
            'lr0': 0.01,
            'momentum': 0.937,
            'weight_decay': 0.0005,
            'save': True,
            'plots': True
        }
    elif config_type == 'val':
        return {
            'data': 'data.yaml',
            'imgsz': 640,
            'batch': 16,
            'conf': 0.25,
            'iou': 0.7,
            'save_txt': True,
            'save_conf': True
        }
    else:
        return {}

def merge_config(args: argparse.Namespace, yaml_config: Optional[Dict[str, Any]] = None, mode: str = 'train') -> Tuple[argparse.Namespace, argparse.Namespace]:
    """
    åˆå¹¶å‘½ä»¤è¡Œå‚æ•°ã€YAMLé…ç½®æ–‡ä»¶å‚æ•°å’Œé»˜è®¤å‚æ•°ï¼ŒæŒ‰ä¼˜å…ˆçº§CLI > YAML > é»˜è®¤å€¼

    Args:
        args: é€šè¿‡argparseè§£æçš„å‚æ•°
        yaml_config: ä»YAMLé…ç½®æ–‡ä»¶ä¸­åŠ è½½çš„å‚æ•°
        mode: è¿è¡Œæ¨¡å¼ï¼Œæ”¯æŒtrain, val, infer

    Returns:
        Tuple[argparse.Namespace, argparse.Namespace]: (yolo_args, project_args)
    """
    # è·å–é»˜è®¤é…ç½®
    default_config = get_default_config(mode)

    # åˆå§‹åŒ–å‚æ•°å­˜å‚¨
    project_args = argparse.Namespace()
    yolo_args = argparse.Namespace()
    merged_params = default_config.copy()

    # åˆå¹¶YAMLå‚æ•°
    if hasattr(args, 'use_yaml') and getattr(args, 'use_yaml', False) and yaml_config:
        for key, value in yaml_config.items():
            merged_params[key] = value
        logger.debug(f"åˆå¹¶YAMLå‚æ•°å: {merged_params}")

    # åˆå¹¶å‘½ä»¤è¡Œå‚æ•°ï¼Œå…·æœ‰æœ€é«˜ä¼˜å…ˆçº§
    cmd_args = {k: v for k, v in vars(args).items() if v is not None}
    for key, value in cmd_args.items():
        merged_params[key] = value
        setattr(project_args, f"{key}_specified", True)

    # åˆ†ç¦»YOLOå‚æ•°å’Œé¡¹ç›®å‚æ•°
    yolo_param_keys = {
        'data', 'epochs', 'batch', 'imgsz', 'device', 'lr0', 'lrf', 'momentum',
        'weight_decay', 'hsv_h', 'hsv_s', 'hsv_v', 'degrees', 'translate',
        'scale', 'shear', 'perspective', 'flipud', 'fliplr', 'mosaic', 'mixup',
        'workers', 'cache', 'rect', 'cos_lr', 'close_mosaic', 'amp', 'fraction',
        'profile', 'freeze', 'project', 'name', 'resume', 'pretrained'
    }

    for key, value in merged_params.items():
        if key in yolo_param_keys:
            setattr(yolo_args, key, value)
        setattr(project_args, key, value)

    return yolo_args, project_args

# ==================== ç³»ç»Ÿä¿¡æ¯è®°å½•åŠŸèƒ½ ====================

def format_bytes(bytes_value):
    """æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºå¯è¯»æ ¼å¼"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} PB"

def get_device_info():
    """è·å–è®¾å¤‡ä¿¡æ¯"""
    device_info = {
        "ç³»ç»Ÿä¿¡æ¯": {
            "æ“ä½œç³»ç»Ÿ": f"{platform.system()} {platform.release()}",
            "Pythonç‰ˆæœ¬": platform.python_version(),
            "å¤„ç†å™¨": platform.processor() or "æœªçŸ¥"
        }
    }

    if HAS_PSUTIL:
        # CPUä¿¡æ¯
        device_info["CPUä¿¡æ¯"] = {
            "ç‰©ç†æ ¸å¿ƒæ•°": psutil.cpu_count(logical=False),
            "é€»è¾‘æ ¸å¿ƒæ•°": psutil.cpu_count(logical=True),
            "CPUä½¿ç”¨ç‡": f"{psutil.cpu_percent(interval=1):.1f}%"
        }

        # å†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        device_info["å†…å­˜ä¿¡æ¯"] = {
            "æ€»å†…å­˜": format_bytes(memory.total),
            "å¯ç”¨å†…å­˜": format_bytes(memory.available),
            "å·²ç”¨å†…å­˜": format_bytes(memory.used),
            "å†…å­˜ä½¿ç”¨ç‡": f"{memory.percent:.1f}%"
        }

        # ç£ç›˜ä¿¡æ¯
        disk = psutil.disk_usage('/')
        device_info["ç£ç›˜ä¿¡æ¯"] = {
            "æ€»ç©ºé—´": format_bytes(disk.total),
            "å·²ç”¨ç©ºé—´": format_bytes(disk.used),
            "å‰©ä½™ç©ºé—´": format_bytes(disk.free),
            "ä½¿ç”¨ç‡": f"{disk.percent:.1f}%"
        }

        # GPUä¿¡æ¯ï¼ˆå°è¯•è·å–ï¼‰
        try:
            import torch
            if torch.cuda.is_available():
                gpu_info = []
                for i in range(torch.cuda.device_count()):
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory
                    gpu_info.append({
                        "GPUåç§°": gpu_name,
                        "æ˜¾å­˜": format_bytes(gpu_memory)
                    })
                device_info["GPUä¿¡æ¯"] = gpu_info
            else:
                device_info["GPUä¿¡æ¯"] = [{"ä¿¡æ¯": "æœªæ£€æµ‹åˆ°CUDAå¯ç”¨GPU"}]
        except ImportError:
            device_info["GPUä¿¡æ¯"] = [{"ä¿¡æ¯": "PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æµ‹GPU"}]

    return device_info

def log_device_info(logger_instance=None):
    """è®°å½•è®¾å¤‡ä¿¡æ¯åˆ°æ—¥å¿—"""
    if logger_instance is None:
        logger_instance = logger

    device_info = get_device_info()

    logger_instance.info("=" * 50)
    logger_instance.info("è®¾å¤‡ä¿¡æ¯æ¦‚è§ˆ")
    logger_instance.info("=" * 50)

    for category, info in device_info.items():
        if category == "GPUä¿¡æ¯":
            logger_instance.info(f"{category}:")
            for gpu_idx, gpu_detail in enumerate(info):
                if "æœªæ£€æµ‹åˆ°CUDAå¯ç”¨GPU" in gpu_detail.get("ä¿¡æ¯", ""):
                    logger_instance.info(f"  {gpu_detail['ä¿¡æ¯']}")
                    break
                logger_instance.info(f"  --- GPU {gpu_idx} è¯¦æƒ… ---")
                for key, value in gpu_detail.items():
                    logger_instance.info(f"    {key}: {value}")
        else:
            logger_instance.info(f"{category}:")
            for key, value in info.items():
                logger_instance.info(f"    {key}: {value}")

    logger_instance.info("=" * 50)
    return device_info

# ==================== æ•°æ®é›†ä¿¡æ¯è®°å½•åŠŸèƒ½ ====================

def get_dataset_info(data_config_name: str, mode: str = "train") -> Tuple[int, list, int, str]:
    """
    è·å–æ•°æ®é›†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç±»åˆ«æ•°ï¼Œç±»åˆ«åç§°å’Œæ ·æœ¬æ•°é‡

    Args:
        data_config_name: æ•°æ®é›†çš„é…ç½®æ–‡ä»¶åç§°ï¼ˆå¦‚ "data.yaml"ï¼‰
        mode: æ¨¡å¼ï¼Œå¯é€‰å€¼ä¸º "train", "val", "test", "infer"

    Returns:
        tuple: (ç±»åˆ«æ•°, ç±»åˆ«åç§°åˆ—è¡¨, æ ·æœ¬æ•°, æ ·æœ¬æ¥æºæè¿°)
    """
    # åˆå§‹åŒ–è¿”å›å€¼
    nc = 0
    classes_names = []
    samples = 0
    source = "æœªçŸ¥"

    # æ¨ç†æ¨¡å¼ä¸‹ä¸æä¾›æ•°æ®é›†æ¥æºä¿¡æ¯
    if mode == 'infer':
        return 0, [], 0, "æ¨ç†æ¨¡å¼ï¼Œä¸æä¾›æ•°æ®é›†æ¥æºä¿¡æ¯"

    try:
        # å°è¯•è¯»å–æ•°æ®é…ç½®æ–‡ä»¶
        data_config_path = Path(data_config_name)
        if not data_config_path.exists():
            # å°è¯•åœ¨é…ç½®ç›®å½•ä¸­æŸ¥æ‰¾
            config_paths = get_config_paths()
            data_config_path = config_paths.get('configs_dir', Path('configs')) / data_config_name

        if data_config_path.exists():
            data_config = read_yaml(data_config_path)
            if data_config:
                # è·å–ç±»åˆ«ä¿¡æ¯
                nc = data_config.get('nc', 0)
                classes_names = data_config.get('names', [])

                # è·å–æ•°æ®è·¯å¾„
                data_paths = {
                    'train': data_config.get('train', ''),
                    'val': data_config.get('val', ''),
                    'test': data_config.get('test', '')
                }

                # ç»Ÿè®¡æ ·æœ¬æ•°é‡
                if mode in data_paths and data_paths[mode]:
                    data_path = Path(data_paths[mode])
                    if data_path.exists():
                        if data_path.is_dir():
                            # å¦‚æœæ˜¯ç›®å½•ï¼Œç»Ÿè®¡å›¾åƒæ–‡ä»¶æ•°é‡
                            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
                            samples = len([f for f in data_path.rglob('*') if f.suffix.lower() in image_extensions])
                            source = f"ç›®å½•: {data_path}"
                        else:
                            # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œè¯»å–æ–‡ä»¶è¡Œæ•°
                            try:
                                with open(data_path, 'r', encoding='utf-8') as f:
                                    samples = len(f.readlines())
                                source = f"æ–‡ä»¶: {data_path}"
                            except Exception:
                                samples = 0
                                source = f"æ–‡ä»¶è¯»å–å¤±è´¥: {data_path}"
                    else:
                        source = f"è·¯å¾„ä¸å­˜åœ¨: {data_paths[mode]}"
                else:
                    source = f"é…ç½®ä¸­æœªæ‰¾åˆ°{mode}è·¯å¾„"
            else:
                source = f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {data_config_path}"
        else:
            source = f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_config_name}"

    except Exception as e:
        logger.error(f"è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {e}")
        source = f"è·å–ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"

    return nc, classes_names, samples, source

def log_dataset_info(data_config_name: str, mode: str = 'train', logger_instance=None) -> dict:
    """
    è·å–å¹¶è®°å½•æ•°æ®é›†ä¿¡æ¯åˆ°æ—¥å¿—

    Args:
        data_config_name: æ•°æ®é›†çš„é…ç½®æ–‡ä»¶åç§°
        mode: æ¨¡å¼ï¼Œå¯é€‰å€¼ä¸º "train", "val", "test", "infer"
        logger_instance: æ—¥å¿—è®°å½•å™¨å®ä¾‹

    Returns:
        dict: ç»“æ„åŒ–çš„æ•°æ®é›†ä¿¡æ¯å­—å…¸
    """
    if logger_instance is None:
        logger_instance = logger

    nc, classes_names, samples, source = get_dataset_info(data_config_name, mode)

    logger_instance.info("=" * 50)
    logger_instance.info(f"æ•°æ®é›†ä¿¡æ¯ ({mode.capitalize()} æ¨¡å¼)")
    logger_instance.info("-" * 50)
    logger_instance.info(f"{'Config File':<20}: {data_config_name}")
    logger_instance.info(f"{'Class Count':<20}: {nc}")
    logger_instance.info(f"{'Class Names':<20}: {', '.join(classes_names) if classes_names else 'æœªçŸ¥'}")
    logger_instance.info(f"{'Sample Count':<20}: {samples}")
    logger_instance.info(f"{'Data Source':<20}: {source}")
    logger_instance.info("-" * 50)

    return {
        "config_file": data_config_name,
        "mode": mode,
        "class_count": nc,
        "class_names": classes_names,
        "sample_count": samples,
        "data_source": source
    }

# ==================== å‚æ•°è®°å½•åŠŸèƒ½ ====================

def log_parameters(project_args, logger_instance=None):
    """
    è®°å½•å‚æ•°æ¥æºå’Œè¯¦ç»†çš„è®­ç»ƒå‚æ•°ä¿¡æ¯

    Args:
        project_args: é¡¹ç›®å‚æ•°å‘½åç©ºé—´
        logger_instance: æ—¥å¿—è®°å½•å™¨å®ä¾‹
    """
    if logger_instance is None:
        logger_instance = logger

    logger_instance.info("=" * 50)
    logger_instance.info("è®­ç»ƒå‚æ•°è¯¦æƒ…")
    logger_instance.info("-" * 50)

    # è®°å½•å‚æ•°æ¥æº
    specified_params = []
    for attr_name in dir(project_args):
        if attr_name.endswith('_specified') and getattr(project_args, attr_name, False):
            param_name = attr_name.replace('_specified', '')
            specified_params.append(param_name)

    if specified_params:
        logger_instance.info(f"å‘½ä»¤è¡ŒæŒ‡å®šå‚æ•°: {', '.join(specified_params)}")
    else:
        logger_instance.info("å‘½ä»¤è¡ŒæŒ‡å®šå‚æ•°: æ— ")

    # è®°å½•æ‰€æœ‰å‚æ•°
    logger_instance.info("\næ‰€æœ‰è®­ç»ƒå‚æ•°:")
    for attr_name in sorted(dir(project_args)):
        if not attr_name.startswith('_') and not attr_name.endswith('_specified'):
            value = getattr(project_args, attr_name)
            logger_instance.info(f"  {attr_name:<20}: {value}")

    logger_instance.info("-" * 50)

# ==================== è®­ç»ƒç»“æœè®°å½•åŠŸèƒ½ ====================

def log_results(results, logger_instance=None, model_trainer=None) -> dict:
    """
    è®°å½•YOLOæ¨¡å‹è®­ç»ƒç»“æœä¿¡æ¯

    Args:
        results: Ultralyticsçš„è®­ç»ƒç»“æœå¯¹è±¡
        logger_instance: æ—¥å¿—è®°å½•å™¨å®ä¾‹
        model_trainer: Ultralyticsçš„Trainerå¯¹è±¡

    Returns:
        dict: åŒ…å«æ¨¡å‹è¯„ä¼°ç»“æœçš„ç»“æ„åŒ–å­—å…¸
    """
    if logger_instance is None:
        logger_instance = logger

    logger_instance.info("=" * 50)
    logger_instance.info("è®­ç»ƒç»“æœæ¦‚è§ˆ")
    logger_instance.info("-" * 50)

    result_info = {}

    try:
        # è·å–ä¿å­˜ç›®å½•
        save_dir = None
        if hasattr(results, 'save_dir') and results.save_dir:
            save_dir = str(results.save_dir)
        elif model_trainer and hasattr(model_trainer, 'save_dir'):
            save_dir = str(model_trainer.save_dir)

        if save_dir:
            result_info['save_dir'] = save_dir
            logger_instance.info(f"{'ä¿å­˜ç›®å½•':<20}: {save_dir}")

        # å°è¯•è·å–è®­ç»ƒæŒ‡æ ‡
        if hasattr(results, 'box') and results.box:
            metrics = results.box
            if hasattr(metrics, 'map50'):
                result_info['map50'] = float(metrics.map50)
                logger_instance.info(f"{'mAP@0.5':<20}: {metrics.map50:.4f}")
            if hasattr(metrics, 'map'):
                result_info['map50_95'] = float(metrics.map)
                logger_instance.info(f"{'mAP@0.5:0.95':<20}: {metrics.map:.4f}")
            if hasattr(metrics, 'mp'):
                result_info['precision'] = float(metrics.mp)
                logger_instance.info(f"{'Precision':<20}: {metrics.mp:.4f}")
            if hasattr(metrics, 'mr'):
                result_info['recall'] = float(metrics.mr)
                logger_instance.info(f"{'Recall':<20}: {metrics.mr:.4f}")

        # è®°å½•è®­ç»ƒæ—¶é—´ä¿¡æ¯
        if hasattr(results, 'speed') and results.speed:
            speed_info = results.speed
            for key, value in speed_info.items():
                result_info[f'speed_{key}'] = value
                logger_instance.info(f"{'Speed ' + key:<20}: {value:.2f}ms")

        # è®°å½•æœ€ä½³æƒé‡è·¯å¾„
        if save_dir:
            best_weights = Path(save_dir) / "weights" / "best.pt"
            last_weights = Path(save_dir) / "weights" / "last.pt"

            if best_weights.exists():
                result_info['best_weights'] = str(best_weights)
                logger_instance.info(f"{'æœ€ä½³æƒé‡':<20}: {best_weights}")

            if last_weights.exists():
                result_info['last_weights'] = str(last_weights)
                logger_instance.info(f"{'æœ€ç»ˆæƒé‡':<20}: {last_weights}")

        result_info['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        logger_instance.info(f"{'å®Œæˆæ—¶é—´':<20}: {result_info['timestamp']}")

    except Exception as e:
        logger_instance.error(f"è®°å½•è®­ç»ƒç»“æœæ—¶å‡ºé”™: {e}")
        result_info['error'] = str(e)

    logger_instance.info("-" * 50)
    return result_info

# ==================== æ—¥å¿—æ–‡ä»¶ç®¡ç†åŠŸèƒ½ ====================

def rename_log_file(logger_instance, save_dir: str, model_name: str):
    """
    é‡å‘½åæ—¥å¿—æ–‡ä»¶ï¼Œæ·»åŠ æ¨¡å‹åç§°å’Œä¿å­˜ç›®å½•ä¿¡æ¯

    Args:
        logger_instance: æ—¥å¿—è®°å½•å™¨å®ä¾‹
        save_dir: è®­ç»ƒç»“æœä¿å­˜ç›®å½•
        model_name: æ¨¡å‹åç§°
    """
    try:
        # è·å–å½“å‰æ—¥å¿—æ–‡ä»¶è·¯å¾„
        for handler in logger_instance.handlers:
            if isinstance(handler, logging.FileHandler):
                current_log_path = Path(handler.baseFilename)

                # ç”Ÿæˆæ–°çš„æ—¥å¿—æ–‡ä»¶å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                new_log_name = f"train_{model_name}_{timestamp}.log"
                new_log_path = current_log_path.parent / new_log_name

                # å…³é—­å½“å‰æ–‡ä»¶å¤„ç†å™¨
                handler.close()
                logger_instance.removeHandler(handler)

                # é‡å‘½åæ–‡ä»¶
                if current_log_path.exists():
                    shutil.move(str(current_log_path), str(new_log_path))
                    logger_instance.info(f"æ—¥å¿—æ–‡ä»¶å·²é‡å‘½å: {new_log_path}")

                # åˆ›å»ºæ–°çš„æ–‡ä»¶å¤„ç†å™¨
                new_handler = logging.FileHandler(new_log_path, encoding='utf-8')
                new_handler.setLevel(handler.level)
                new_handler.setFormatter(handler.formatter)
                logger_instance.addHandler(new_handler)

                break

    except Exception as e:
        logger.error(f"é‡å‘½åæ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")

# ==================== æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†åŠŸèƒ½ ====================

def copy_checkpoint_models(save_dir: Path, model_name: str, checkpoints_dir: Path, logger_instance=None):
    """
    å¤åˆ¶è®­ç»ƒæ£€æŸ¥ç‚¹æ¨¡å‹åˆ°æŒ‡å®šç›®å½•

    Args:
        save_dir: è®­ç»ƒç»“æœä¿å­˜ç›®å½•
        model_name: æ¨¡å‹åç§°
        checkpoints_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
        logger_instance: æ—¥å¿—è®°å½•å™¨å®ä¾‹
    """
    if logger_instance is None:
        logger_instance = logger

    try:
        # ç¡®ä¿æ£€æŸ¥ç‚¹ç›®å½•å­˜åœ¨
        checkpoints_dir.mkdir(parents=True, exist_ok=True)

        weights_dir = save_dir / "weights"
        if not weights_dir.exists():
            logger_instance.warning(f"æƒé‡ç›®å½•ä¸å­˜åœ¨: {weights_dir}")
            return

        # å¤åˆ¶æœ€ä½³æ¨¡å‹
        best_model = weights_dir / "best.pt"
        if best_model.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            dest_best = checkpoints_dir / f"{model_name}_best_{timestamp}.pt"
            shutil.copy2(best_model, dest_best)
            logger_instance.info(f"æœ€ä½³æ¨¡å‹å·²å¤åˆ¶: {dest_best}")

        # å¤åˆ¶æœ€ç»ˆæ¨¡å‹
        last_model = weights_dir / "last.pt"
        if last_model.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            dest_last = checkpoints_dir / f"{model_name}_last_{timestamp}.pt"
            shutil.copy2(last_model, dest_last)
            logger_instance.info(f"æœ€ç»ˆæ¨¡å‹å·²å¤åˆ¶: {dest_last}")

    except Exception as e:
        logger_instance.error(f"å¤åˆ¶æ£€æŸ¥ç‚¹æ¨¡å‹å¤±è´¥: {e}")

def train_model(config_path: Optional[str] = None,
               data_config_path: Optional[str] = None,
               model_name: str = "yolo11n",  # æ›´æ–°ä¸ºYOLO v11
               epochs: int = 100,
               batch: int = 16,  # ä¿®æ­£å‚æ•°å
               imgsz: int = 640,  # ä¿®æ­£å‚æ•°å
               device: str = "",
               project: str = None,  # å°†ä½¿ç”¨é¡¹ç›®é»˜è®¤è·¯å¾„
               name: str = "exp",
               resume: bool = False,
               pretrained: bool = True,
               use_yaml: bool = True,  # æ·»åŠ YAMLé…ç½®æ”¯æŒ
               **kwargs) -> bool:
    """
    è®­ç»ƒYOLOæ¨¡å‹

    Args:
        config_path: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        data_config_path: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        model_name: æ¨¡å‹åç§°
        epochs: è®­ç»ƒè½®æ•°
        batch: æ‰¹æ¬¡å¤§å°
        imgsz: è¾“å…¥å›¾åƒå°ºå¯¸
        device: è®­ç»ƒè®¾å¤‡
        project: é¡¹ç›®ç›®å½•
        name: å®éªŒåç§°
        resume: æ˜¯å¦æ¢å¤è®­ç»ƒ
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        use_yaml: æ˜¯å¦ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶
        **kwargs: å…¶ä»–è®­ç»ƒå‚æ•°

    Returns:
        bool: è®­ç»ƒæ˜¯å¦æˆåŠŸ
    """
    try:
        logger.info("YOLO æ¨¡å‹è®­ç»ƒè„šæœ¬å¯åŠ¨".center(80, "="))

        # 1. åŠ è½½é…ç½®æ–‡ä»¶
        yaml_config = {}
        if use_yaml:
            yaml_config = load_config(config_type='train')

        # 2. åˆ›å»ºå‚æ•°å‘½åç©ºé—´ç”¨äºåˆå¹¶é…ç½®
        args = argparse.Namespace()
        args.data = data_config_path
        args.batch = batch
        args.epochs = epochs
        args.imgsz = imgsz
        args.device = device
        args.weights = f"{model_name}.pt"
        args.use_yaml = use_yaml

        # 3. åˆå¹¶å‚æ•°
        yolo_args, project_args = merge_config(args, yaml_config, mode='train')

        # 4. è®°å½•è®¾å¤‡ä¿¡æ¯
        log_device_info(logger)

        # 5. è·å–æ•°æ®ä¿¡æ¯
        if data_config_path:
            data_file = data_config_path
        else:
            # ä½¿ç”¨é…ç½®ç›®å½•ä¸­çš„data.yaml
            config_paths = get_config_paths()
            data_file = str(config_paths['data_yaml'])

        logger.info(f"ä½¿ç”¨æ•°æ®é…ç½®æ–‡ä»¶: {data_file}")
        log_dataset_info(data_file, mode='train', logger_instance=logger)

        # 6. è®°å½•å‚æ•°æ¥æº
        log_parameters(project_args, logger_instance=logger)

        # 7. å‡†å¤‡è®­ç»ƒé…ç½®
        train_config = {}

        # è®¾ç½®é¡¹ç›®è·¯å¾„ - ä½¿ç”¨é¡¹ç›®ç»“æ„
        if project is None:
            model_paths = get_model_paths()
            project = str(model_paths['models_dir'].parent / "runs" / "train")

        train_config.update({
            'epochs': epochs,
            'batch': batch,
            'imgsz': imgsz,
            'device': device,
            'project': project,
            'name': name,
            'resume': resume,
            'pretrained': pretrained
        })

        # è¿‡æ»¤kwargsï¼Œåªä¿ç•™æœ‰æ•ˆçš„YOLOå‚æ•°ï¼Œé¿å…å‚æ•°åå†²çª
        valid_yolo_params = {
            'lr0', 'lrf', 'momentum', 'weight_decay', 'hsv_h', 'hsv_s', 'hsv_v',
            'degrees', 'translate', 'scale', 'shear', 'perspective', 'flipud', 'fliplr',
            'mosaic', 'mixup', 'workers', 'cache', 'rect', 'cos_lr', 'close_mosaic',
            'amp', 'fraction', 'profile', 'freeze'
        }

        # åªæ·»åŠ æœ‰æ•ˆçš„YOLOå‚æ•°
        for key, value in kwargs.items():
            if key in valid_yolo_params:
                train_config[key] = value

        # 8. æ£€æŸ¥æ˜¯å¦å®‰è£…äº†ultralytics
        try:
            from ultralytics import YOLO
        except ImportError:
            logger.error("è¯·å®‰è£…ultralytics: pip install ultralytics")
            return False

        # 9. åˆå§‹åŒ–æ¨¡å‹
        logger.info(f"åˆå§‹åŒ–æ¨¡å‹ï¼ŒåŠ è½½æ¨¡å‹: {project_args.weights}")

        # ä¼˜å…ˆä»é¡¹ç›®é¢„è®­ç»ƒç›®å½•æŸ¥æ‰¾
        model_paths = get_model_paths()
        pretrained_model = model_paths['pretrained'] / project_args.weights

        if pretrained_model.exists():
            model_path = str(pretrained_model)
            logger.info(f"ä½¿ç”¨é¡¹ç›®é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        else:
            # å¦‚æœé¡¹ç›®ç›®å½•æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
            model_path = project_args.weights
            logger.info(f"ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰: {model_path}")
            logger.info(f"å»ºè®®å°†é¢„è®­ç»ƒæ¨¡å‹æ”¾å…¥: {model_paths['pretrained']}")

        if not Path(model_path).exists() and not model_path.endswith('.yaml'):
            logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        model = YOLO(model_path)

        # 10. ä½¿ç”¨time_itè£…é¥°å™¨æ‰§è¡Œè®­ç»ƒ
        @time_it(iterations=1, name="æ¨¡å‹è®­ç»ƒ", logger_instance=logger)
        def run_training(model_instance, train_args):
            return model_instance.train(**train_args)

        # å¼€å§‹è®­ç»ƒ
        logger.info("å¼€å§‹è®­ç»ƒ...")
        logger.info(f"è®­ç»ƒå‚æ•°: {train_config}")

        results = run_training(model, {
            'data': data_file,
            **train_config
        })

        # 11. è®°å½•ç»“æœä¿¡æ¯
        log_results(results, logger_instance=logger, model_trainer=model.trainer)

        # 12. é‡å‘½åæ—¥å¿—æ–‡ä»¶
        model_name_for_log = project_args.weights.replace(".pt", "")
        rename_log_file(logger, str(model.trainer.save_dir), model_name_for_log)

        # 13. å¤åˆ¶æ£€æŸ¥ç‚¹æ¨¡å‹
        checkpoints_dir = model_paths.get('checkpoints', Path('checkpoints'))
        copy_checkpoint_models(Path(model.trainer.save_dir),
                             project_args.weights,
                             checkpoints_dir,
                             logger_instance=logger)

        logger.info("YOLO æ¨¡å‹è®­ç»ƒè„šæœ¬ç»“æŸ")
        return True

    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
        return False

def resume_training(checkpoint_path: str, **kwargs) -> bool:
    """
    æ¢å¤è®­ç»ƒ
    
    Args:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        **kwargs: å…¶ä»–è®­ç»ƒå‚æ•°
        
    Returns:
        bool: æ¢å¤è®­ç»ƒæ˜¯å¦æˆåŠŸ
    """
    try:
        checkpoint_path = Path(checkpoint_path)
        
        if not checkpoint_path.exists():
            logger.error(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return False
        
        logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {checkpoint_path}")
        
        from ultralytics import YOLO
        model = YOLO(str(checkpoint_path))
        
        # æ¢å¤è®­ç»ƒ
        results = model.train(resume=True, **kwargs)
        
        logger.info("æ¢å¤è®­ç»ƒå®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"æ¢å¤è®­ç»ƒå¤±è´¥: {e}")
        return False

def export_model(model_path: str, 
                format: str = "onnx",
                img_size: int = 640,
                half: bool = False,
                dynamic: bool = False,
                simplify: bool = True,
                **kwargs) -> bool:
    """
    å¯¼å‡ºæ¨¡å‹
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        format: å¯¼å‡ºæ ¼å¼ (onnx, torchscript, tflite, etc.)
        img_size: è¾“å…¥å›¾åƒå°ºå¯¸
        half: æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦
        dynamic: æ˜¯å¦ä½¿ç”¨åŠ¨æ€è¾“å…¥å°ºå¯¸
        simplify: æ˜¯å¦ç®€åŒ–ONNXæ¨¡å‹
        **kwargs: å…¶ä»–å¯¼å‡ºå‚æ•°
        
    Returns:
        bool: å¯¼å‡ºæ˜¯å¦æˆåŠŸ
    """
    try:
        model_path = Path(model_path)
        
        if not model_path.exists():
            logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        
        logger.info(f"å¯¼å‡ºæ¨¡å‹: {model_path} -> {format}")
        
        from ultralytics import YOLO
        model = YOLO(str(model_path))
        
        # å¯¼å‡ºæ¨¡å‹
        export_path = model.export(
            format=format,
            imgsz=img_size,
            half=half,
            dynamic=dynamic,
            simplify=simplify,
            **kwargs
        )
        
        logger.info(f"æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {export_path}")
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹å¯¼å‡ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°"""
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤é…ç½®ç›´æ¥è¿è¡Œ
    if len(sys.argv) == 1:
        print("ğŸš€ æ£€æµ‹åˆ°ç›´æ¥è¿è¡Œæ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤é…ç½®å¼€å§‹è®­ç»ƒ...")
        print("ğŸ’¡ å¦‚éœ€è‡ªå®šä¹‰å‚æ•°ï¼Œè¯·ä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼ï¼špython train.py --help")

        # ç›´æ¥è¿è¡Œè®­ç»ƒï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
        success = train_model()

        if success:
            print("âœ… è®­ç»ƒæˆåŠŸå®Œæˆ")
            sys.exit(0)
        else:
            print("âŒ è®­ç»ƒå¤±è´¥")
            sys.exit(1)

    # æœ‰å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œæ­£å¸¸è§£æå‚æ•°
    parser = argparse.ArgumentParser(description="YOLOæ¨¡å‹è®­ç»ƒè„šæœ¬")

    # åŸºæœ¬å‚æ•°
    parser.add_argument("--config", type=str, help="æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--data", type=str, help="æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", type=str, default="yolo11n", help="æ¨¡å‹åç§°")
    parser.add_argument("--epochs", type=int, default=100, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")  # ä¿®æ­£å‚æ•°å
    parser.add_argument("--imgsz", type=int, default=640, help="è¾“å…¥å›¾åƒå°ºå¯¸")  # ä¿®æ­£å‚æ•°å
    parser.add_argument("--device", type=str, default="", help="è®­ç»ƒè®¾å¤‡")
    parser.add_argument("--project", type=str, default="runs/train", help="é¡¹ç›®ç›®å½•")
    parser.add_argument("--name", type=str, default="exp", help="å®éªŒåç§°")

    # è®­ç»ƒé€‰é¡¹
    parser.add_argument("--resume", action="store_true", help="æ¢å¤è®­ç»ƒ")
    parser.add_argument("--no-pretrained", action="store_true", help="ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡")
    parser.add_argument("--use-yaml", action="store_true", default=True, help="ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶")
    
    # å­¦ä¹ ç‡å‚æ•°
    parser.add_argument("--lr0", type=float, default=0.01, help="åˆå§‹å­¦ä¹ ç‡")
    parser.add_argument("--lrf", type=float, default=0.01, help="æœ€ç»ˆå­¦ä¹ ç‡")
    parser.add_argument("--momentum", type=float, default=0.937, help="SGDåŠ¨é‡")
    parser.add_argument("--weight-decay", type=float, default=0.0005, help="æƒé‡è¡°å‡")
    
    # æ•°æ®å¢å¼ºå‚æ•°
    parser.add_argument("--hsv-h", type=float, default=0.015, help="è‰²è°ƒå¢å¼º")
    parser.add_argument("--hsv-s", type=float, default=0.7, help="é¥±å’Œåº¦å¢å¼º")
    parser.add_argument("--hsv-v", type=float, default=0.4, help="æ˜åº¦å¢å¼º")
    parser.add_argument("--degrees", type=float, default=0.0, help="æ—‹è½¬è§’åº¦")
    parser.add_argument("--translate", type=float, default=0.1, help="å¹³ç§»")
    parser.add_argument("--scale", type=float, default=0.5, help="ç¼©æ”¾")
    parser.add_argument("--shear", type=float, default=0.0, help="å‰ªåˆ‡")
    parser.add_argument("--perspective", type=float, default=0.0, help="é€è§†å˜æ¢")
    parser.add_argument("--flipud", type=float, default=0.0, help="ä¸Šä¸‹ç¿»è½¬æ¦‚ç‡")
    parser.add_argument("--fliplr", type=float, default=0.5, help="å·¦å³ç¿»è½¬æ¦‚ç‡")
    parser.add_argument("--mosaic", type=float, default=1.0, help="é©¬èµ›å…‹å¢å¼ºæ¦‚ç‡")
    parser.add_argument("--mixup", type=float, default=0.0, help="mixupå¢å¼ºæ¦‚ç‡")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--workers", type=int, default=8, help="æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--cache", action="store_true", help="ç¼“å­˜å›¾åƒ")
    parser.add_argument("--rect", action="store_true", help="çŸ©å½¢è®­ç»ƒ")
    parser.add_argument("--cos-lr", action="store_true", help="ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦")
    parser.add_argument("--close-mosaic", type=int, default=10, help="å…³é—­é©¬èµ›å…‹å¢å¼ºçš„è½®æ•°")
    parser.add_argument("--amp", action="store_true", default=True, help="è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ")
    parser.add_argument("--fraction", type=float, default=1.0, help="æ•°æ®é›†ä½¿ç”¨æ¯”ä¾‹")
    parser.add_argument("--profile", action="store_true", help="æ€§èƒ½åˆ†æ")
    parser.add_argument("--freeze", type=int, help="å†»ç»“å±‚æ•°")
    
    args = parser.parse_args()
    
    # è®¾ç½®ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
    from pathlib import Path
    from datetime import datetime

    # åˆ›å»ºç»Ÿä¸€çš„æ—¥å¿—ç›®å½•
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    # ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—æ–‡ä»¶åï¼ˆæŒ‰æ—¥æœŸï¼‰
    today = datetime.now().strftime("%Y%m%d")
    unified_log_file = log_dir / f"yolo_training_{today}.log"

    # é…ç½®ç»Ÿä¸€æ—¥å¿— - æŒ‡å®šæ—¥å¿—æ–‡ä»¶è·¯å¾„
    setup_logger("train", log_file=unified_log_file, console_output=True, file_output=True)
    
    # å‡†å¤‡è®­ç»ƒå‚æ•°
    train_kwargs = {
        'lr0': args.lr0,
        'lrf': args.lrf,
        'momentum': args.momentum,
        'weight_decay': args.weight_decay,
        'hsv_h': args.hsv_h,
        'hsv_s': args.hsv_s,
        'hsv_v': args.hsv_v,
        'degrees': args.degrees,
        'translate': args.translate,
        'scale': args.scale,
        'shear': args.shear,
        'perspective': args.perspective,
        'flipud': args.flipud,
        'fliplr': args.fliplr,
        'mosaic': args.mosaic,
        'mixup': args.mixup,
        'workers': args.workers,
        'cache': args.cache,
        'rect': args.rect,
        'cos_lr': args.cos_lr,
        'close_mosaic': args.close_mosaic,
        'amp': args.amp,
        'fraction': args.fraction,
        'profile': args.profile,
    }
    
    if args.freeze is not None:
        train_kwargs['freeze'] = args.freeze
    
    # å¼€å§‹è®­ç»ƒ
    success = train_model(
        config_path=args.config,
        data_config_path=args.data,
        model_name=args.model,
        epochs=args.epochs,
        batch=args.batch,  # ä¿®æ­£å‚æ•°å
        imgsz=args.imgsz,  # ä¿®æ­£å‚æ•°å
        device=args.device,
        project=args.project,
        name=args.name,
        resume=args.resume,
        pretrained=not args.no_pretrained,
        use_yaml=args.use_yaml,  # æ·»åŠ YAMLé…ç½®æ”¯æŒ
        **train_kwargs
    )
    
    if success:
        logger.info("è®­ç»ƒæˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        logger.error("è®­ç»ƒå¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()
