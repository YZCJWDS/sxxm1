# 项目初始化与数据集转换与数据验证

**任务3：初始化脚本【作业任务】**

1. 通过初始化脚本自动创建所有必须的目录，确保无论在哪里运行，项目结构保持一致
2. 可复制性和可维护性
3. 做用户指引，提示用户那些需要自己创建和需要用户操作的目录
4. 日志功能，脚本运行需要反馈，让用户那些目录被创建了，那些是已经存在的，那些是有问题的，
5. 性能监控。自动测量脚本核心功能的执行时间。

模块导入问题

定义了： `logging_utils.py`,`paths.py`,`performance_utils.py`

具体脚本内容如下:

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# @FileName  :initialize_project.py
# @Time      :2025/6/24 09:09:24
# @Author    :雨霓同学
# @Project   :BTD
# @Function  :项目初始化脚本，检查并创建必要的项目结构，提示用户将原始数据存放到指定的位置

import logging

from utils import setup_logger
from utils import time_it
from utils import (
    YOLOSERVER_ROOT,  # 项目根目录
    CONFIGS_DIR,  # 配置文件目录
    DATA_DIR,  # 数据集
    RUNS_DIR,  # 模型运行结果 目录
    LOGS_DIR,  # 日志目录
    MODEL_DIR,  #
    PRETRAINED_DIR,  # 预训练模型存放的位置
    CHECKPOINTS_DIR,
    SCRIPTS_DIR,
    RAW_IMAGES_DIR,
    ORIGINAL_ANNOTATIONS_DIR,
    YOLO_STAGED_LABELS_DIR,
)

# 第一步：配置日志记录
logger = setup_logger(base_path=LOGS_DIR,
                        log_type="init_project",
                        model_name=None,
                        log_level=logging.INFO,
                        logger_name="YOLO Initialize Project"
                        )


# 第二步：定义项目初始化函数
@time_it(iterations=1, name="项目初始化",logger_instance=logger)
def initialize_project():
    """
    检查并创建项目所需的文件夹结构
    :return:
    """
    logger.info("开始初始化项目".center(60, "="))
    logger.info(f"当前项目的根目录为：{YOLOSERVER_ROOT.resolve()}")
    created_dirs = []
    existing_dirs = []
    raw_data_status = []

    standard_data_to_create = [
        CONFIGS_DIR,
        DATA_DIR,
        RUNS_DIR,
        MODEL_DIR,
        CHECKPOINTS_DIR,
        PRETRAINED_DIR,
        LOGS_DIR,
        SCRIPTS_DIR,
        DATA_DIR / "train" / "images",
        DATA_DIR / "val" / "images",
        DATA_DIR / "test" / "images",
        DATA_DIR / "train" / "labels",
        DATA_DIR / "val" / "labels",
        DATA_DIR / "test" / "labels",
        YOLO_STAGED_LABELS_DIR,
        ORIGINAL_ANNOTATIONS_DIR,
    ]

    logger.info(f"检查并创建核心项目目录结构".center(80, "="))
    for d in standard_data_to_create:
        if not d.exists():
            try:
                d.mkdir(parents=True, exist_ok=True)
                logger.info(f" 已经创建的目录：{d.relative_to(YOLOSERVER_ROOT)}")
                created_dirs.append(d)
            except Exception as e:
                logger.error(f" 创建目录：{d.relative_to(YOLOSERVER_ROOT)} 失败: {e}")
                created_dirs.append(f" 创建目录：{d.relative_to(YOLOSERVER_ROOT)} 失败: {e}")
        else:
            logger.info(f" 检测到已存在的目录：{d.relative_to(YOLOSERVER_ROOT)}")
            existing_dirs.append(d.relative_to(YOLOSERVER_ROOT))
    logger.info(f"核心项目文件夹结构检查以及创建完成".center(60, "="))

    # 3. 检查原始数据集目录并给出提示
    logger.info(f"开始检查原始数据集目录".center(60, "="))
    raw_dirs_to_check = {
        "原始图像文件": RAW_IMAGES_DIR,
        "原始标注文件": ORIGINAL_ANNOTATIONS_DIR,
    }
    for desc, raw_dir in raw_dirs_to_check.items():
        if not raw_dir.exists():
            msg = (
                f"!! 原始{desc}目录不存在，请将原始数据集数据放置此目录下，"
                f"并确保目录结构正确，以便后续数据集转换正常执行"
            )
            logger.warning(msg)
            logger.warning(f"期望结构为: {raw_dir.resolve()}")
            raw_data_status.append(f"{raw_dir.relative_to(YOLOSERVER_ROOT)}:不存在，需要手动创建并放置原始数据")
        else:
            if not any(raw_dir.iterdir()):
                msg = f"原始{desc}，已经存在，但内容为空，请将原始{desc}放在此目录下，以便后续数据集转换"
                logger.warning(msg)
                raw_data_status.append(f"{raw_dir.relative_to(YOLOSERVER_ROOT)}:已经存在，但内容为空,需要放置原始数据")
            else:
                logger.info(f"原始{desc}，已经存在, {raw_dir.relative_to(YOLOSERVER_ROOT)}包含原始文件")
                raw_data_status.append(f"{raw_dir.relative_to(YOLOSERVER_ROOT)}:已经存在")

    # 第四步：汇总所有的检查结果和创建结果
    logger.info("项目初始化结果汇总".center(80, "="))
    if created_dirs:
        logger.info(f"此次初始化过程中,一共创建了 {len(created_dirs)}个目录，具体内容如下：")
        for d in created_dirs:
            logger.info(f"- {d}")
    else:
        logger.info("本次初始化没有创建任何目录")

    if existing_dirs:
        logger.info(f"此次初始化过程中，一共检查到 {len(existing_dirs)}个 已经存在的目录,具体内容如下:")
        for d in existing_dirs:
            logger.info(f"- {d}")
    if raw_data_status:
        logger.info(f"原始数据集目录检查结果".center(80,'='))
        for s in raw_data_status:
            logger.info(f"- {s}")
    logger.info("请务必根据上述提示进行操作，特别是关于原始数据集目录的检查结果")
    logger.info("初始化项目完成".center(80,'='))

if __name__ == '__main__':
    initialize_project()


```

## 数据集转换任务开发

1. 数据从哪里来？有那些类型的数据？项目中需要的数据格式上什么样子的？我们能找到的数据格式是怎么样的？如何进行数据的转换等、

### 数据从何而来

1. 医疗的机构的数据：往往没有标注信息
2. 公开的医学影像数据集，部分或者全部可能包含标注信息
3. 第三方数据获取.开源数据集
   1. kaggle： https://www.kaggle.com/search
   2. 阿里天池:https://tianchi.aliyun.com/dataset/
   3. 百度飞桨：https://aistudio.baidu.com/datasetoverview
   4. 和鲸社区：https://www.heywhale.com/home/dataset
   5. https://universe.roboflow.com/
4. 传统的方法: 现场采集，照片+视频，然后数据工程师写脚本工具，然后手动标注
5. **获取网络上的数据：照片，视频，然后写解析工具，手动标注**
6. 数据工程师，对已有的图像进行翻转，裁剪，缩放，模糊，亮度调整，饱和度调整，等增强手段。
7. 利用GAN网络生成图像

### 如何标注数据

利用laebeling进行数据标注，LabelMe, 

专业的数据必须要听从专业人员的建议进行标注

### 常见的数据格式有那些？

- Pascal Voc格式， 每一个图像文件，对应一个XML注释文件，包含图像的路径，尺寸，每个目标的详细信息，边界框信息，记录类别名称，和边界框坐标，
- COCO-json格式： 结构复杂，功能强大，包含丰富的标注类型，支持边界框标注还支持实例分割多边形轮廓。
- yolo txt格式：算法组同学用的数据

### 项目中训练使用的数据集是什么样的

- 图像数据
  - 主流的图像格式，PNG,JPG，
  - 图像应该清晰的显示需要检测和分割单肿瘤或病变区域
- 标注数据：
  - 目标检测任务：需要边界信息
  - 实例分割任务：需要像素级别的分割掩膜

## 数据转换核心开发任务需求文档

1、将pascal voc 。 COCO-json转换为yolo txt格式

关键点：

- 支持`coco json`到`yolo txt`的转换

- 支持`pascal voc`到`yolo txt`的转换

- 能够自动提取数据集中所有类别，也可以按照用户指定的类别进行过滤和ID映射

- 具备良好的错误处理机制

- 需要自动的生存data.yaml配置文件，到指定的位置configs目录下

  ```
  path: C:\Users\Matri\Desktop\DTH2\yoloserver\data
  train: C:\Users\Matri\Desktop\DTH2\yoloserver\data\train\images
  val: C:\Users\Matri\Desktop\DTH2\yoloserver\data\val\images
  test: C:\Users\Matri\Desktop\DTH2\yoloserver\data\test\images
  nc: 3
  names: [glioma_tumor, meningioma_tumor, pituitary_tumor]
  ```

如何设计

- 最底层：不同的格式有不同的转换工具

- 一个统一的入口：中间转换层。接受输入的目录，输出的目录，原始标注格式类型，和可选的类别作为参数。

- 最顶层：将转换之后的yolo txt数据，划分为训练集，测试集，验证集，图像和标签均位于设定好的位置。并且要求生成对应的data.yaml文件

  ```
  if __name__ == "__main__":
      from ultralytics.data.converter import convert_coco
      convert_coco(
          labels_dir=r"C:\Users\Matri\Desktop\DTH2\yoloserver\data\raw\original_annotations",
          save_dir="dirs"
      )
  ```


## 支持`coco json`到`yolo txt`的转换

1. 完成基本都转换，很好实现。但是有一些技术问题，脚本重复调用会生成递进的目录，这是不允许的。需要将所有的转换后的yolo标签放到一个暂存的目录，后续的转换脚本，利用这个暂存目录中的文件，以及images文件夹，会进行数据集的划分



1. 提取转换的标签列表。[glioma_tumor, meningioma_tumor, pituitary_tumor] 这个列表是返回值

### 核心实现流程

1. 初始化与输入校验，初始化日志,检测文件是否存在，找到所有的json文件，
2. coco类别一致性检查，多个cocojson文件，他们的类别定义是统一的，最终需要claess_name列表，作为返回
3. 实现核心的转换功能，使用`from ultralytics.data.converter import convert_coco`进行转换，为了避免对原始数据造成污染并确保文件隔离。可以让`convert_coco`输出目录为一个带当前时间戳的唯一临时目录。
4. 文件的剪切与清理：遍历`convert_coco`输出目录，将里面所有的yolo txt剪切或者移动到，临时文件区即可，移动完成之后，删除临时目录
5. 返回结果，任务结束



```
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# @FileName  :coco.py
# @Time      :2025/6/24 14:40:16
# @Author    :雨霓同学
# @Project   :BTD
# @Function  : 主要实现coco json转yolo格式，并返回一个名称列表，
import json
import logging
import datetime
import shutil
from pathlib import Path

from ultralytics.data.converter import convert_coco

from paths import RAW_DATA_DIR, YOLO_STAGED_LABELS_DIR

logger = logging.getLogger(__name__)

def convert_coco_json_to_yolo(json_input_dir: Path, task: str = "detection",cls91to80: bool = False):
    """
    将coco json标注文件转换为yolo格式的txt文件到指定的目录
    :param cls91to80: 是否将coco 91类映射到80类
    :param json_input_dir: 包含coco json的目录
    :param task: 任务类型
    :return: class_name:检测对象名称列表
    """
    logger.info(f"开始转换coco json标注文件,从{json_input_dir} 转为YOLO格式【自动模式】")

    if not json_input_dir.exists():
        logger.error(f"coco json输入目录: {json_input_dir} 不存在")
        raise FileNotFoundError(f"coco json输入目录: {json_input_dir} 不存在")

    # 1. 查找目录中所有的Json文件并提示数量
    json_files_found = list(json_input_dir.glob("*.json"))
    if not json_files_found:
        logger.error(f"coco json输入目录: {json_input_dir} 中不存在json文件")
        raise FileNotFoundError(f"coco json输入目录: {json_input_dir} 中不存在json文件")
    logger.info(f"coco json输入目录: {json_input_dir} 中找到 {len(json_files_found)} 个json文件")

    # 2. 判断json文件的 'categories' 是否相同并收集使用 category_id
    first_categories_set = set()
    first_coco_json_path = json_files_found[0]
    all_used_category_ids = set()
    original_coco_id_to_name_map = {}

    for i, json_file_path in enumerate(json_files_found):
        try:
            with open(json_file_path, "r", encoding="utf-8") as f:
                current_coco_data = json.load(f)
            current_categories_set = set()
            for cat in current_coco_data.get('categories', []):
                if 'id' in cat and 'name' in cat:
                    current_categories_set.add((cat['id'], cat['name']))
            for ann in current_coco_data.get('annotations', []):
                if 'category_id' in ann:
                    all_used_category_ids.add(ann['category_id'])

            if i == 0:
                first_categories_set = current_categories_set
                for cat in current_coco_data.get('categories', []):
                    if 'id' in cat and 'name' in cat:
                        original_coco_id_to_name_map[cat['id']] = cat['name']
                logger.info(f"已加载基准json文件：'{json_file_path.name}'的categories信息，"
                            f"并构建原始ID到名称的映射关系。")
            else:
                if first_categories_set != current_categories_set:
                    logger.critical(f"数据集存在严重错误！Json文件 '{json_file_path.name}' "
                                f"的categories信息与第一个'{first_coco_json_path.name}'文件不一致！请检查！")
                    raise ValueError(f"数据集存在严重错误！Json文件 '{json_file_path.name}' "
                                f"的categories信息与第一个'{first_coco_json_path.name}'文件不一致！请检查！")
                logger.info(f"Json文件 '{json_file_path.name}'的categories 与定义的基准文件一致！")
        except json.JSONDecodeError as e:
            logger.error(f"Json文件 '{json_file_path.name}' 解析错误！: {e}")
            raise
        except Exception as e:
            logger.error(f"读取或者处理 coco json文件 {json_file_path.name} 时发生错误！: {e}")
            raise
    # 3. 提取实际使用的类别ID并构建最终的classes_name列表，用于data.yaml的names字段
    sorted_used_categories = sorted(list(all_used_category_ids))

    classes_name = []
    for cat_id in sorted_used_categories:
        if cat_id in original_coco_id_to_name_map:
            classes_name.append(original_coco_id_to_name_map[cat_id])
        else:
            logger.warning(f"在 annotations 中发现 category_id {cat_id} "
                        f"但是在 categories 中没有找到对应的名称，将跳过此ID")
    if not classes_name:
        logger.error("未能从所有的json文件中的annotations中找到任何类别，转换终止")
        return []
    logger.info(f"根据所有的JSon文件的annotations构建的最终列表为：{classes_name}")
    if cls91to80:
        logger.info(f"注意：'cls91to80'参数为True,ultralytics将在内部对列表ID进行映射，"
                    f"但是本函数返回到classes_name列表是基于原始coco列表和标注中使用情况决定的")

    # 4. 定义文件处理逻辑
    # 1. 生成一个基于当前时间唯一的临时目录名
    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S_%f")
    temp_dir_name = f"{timestamp}"
    temp_dir = RAW_DATA_DIR / temp_dir_name

    use_segments = (task == "segmentation")

    # 2. 调用ultralytics的coco2yolo函数
    try:
        _ = convert_coco(
            labels_dir=str(json_input_dir),
            save_dir = str(temp_dir),
            use_segments=use_segments,
            use_keypoints=False,
            cls91to80=cls91to80,
            lvis=False
        )
        logger.info(f"ultralytics.convert_coco转换完成到临时目录{temp_dir}")
    except Exception as e:
        logger.critical(f"转换失败，请检查数据集格式是否正确，错误信息为：{e}")
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
        return []
    # 3. 剪切coco转换的数据到 指定的临时存放点
    source_labels_in_temp = temp_dir / "labels"
    if not source_labels_in_temp.exists():
        logger.error(f"临时转换目录{temp_dir} 中不存在 labels目录，可能是因为转换失败原因")
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
            return []
    # 确保YOLO_STAGED_LABELS_DIR 存在
    YOLO_STAGED_LABELS_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"开始将 生成的TXT 文件从{source_labels_in_temp} 剪切到 {YOLO_STAGED_LABELS_DIR} 中...")

    moved_count = 0
    for txt_file in source_labels_in_temp.glob("./*/*.txt"):
        try:
            shutil.move(str(txt_file), str(YOLO_STAGED_LABELS_DIR / txt_file.name))
            moved_count += 1
        except Exception as e:
            logger.error(f"移动文件{txt_file.name} 到 {YOLO_STAGED_LABELS_DIR}失败，错误信息为：{e}")
        logger.info(f"成功移动了{moved_count}个YOLO TXT 文件，到 {YOLO_STAGED_LABELS_DIR}")

    # 删除临时目录
    try:
        shutil.rmtree(temp_dir)
        logger.info(f"成功删除临时目录 {temp_dir}")
    except Exception as e:
        logger.error(f"删除临时目录{source_labels_in_temp}失败，错误信息为：{e}")
    logger.info(f"COCO JSON 到 YOLO TXT 转换流程完成".center(60, "="))

    return classes_name


if __name__=="__main__":
    classes_name_ = convert_coco_json_to_yolo(
        json_input_dir=Path(r"C:\Users\Matri\Desktop\BTD\yoloserver\data\raw\original_annotations"),
        task = "detection",
    )
    print(classes_name_)
```

### 中间层转换逻辑

1. 为项目提供一个单点入口,屏蔽底层不同标注的转换复杂性,根据用户传入的参数,决定调用什么转换模块,

   ```
   #!/usr/bin/env python
   # -*- coding:utf-8 -*-
   # @FileName  :data_utils.py
   # @Time      :2025/6/24 15:56:45
   # @Author    :雨霓同学
   # @Project   :BTD
   # @Function  :中层转换器,根据顶层用户参数,决定调用那个底层转换器
   import logging
   from pathlib import Path
   
   from paths import YOLO_STAGED_LABELS_DIR
   from data_converters.coco import convert_coco_json_to_yolo
   from data_converters.pascal_voc import convert_pascal_voc_to_yolo
   
   logger = logging.getLogger(__name__)
   
   def convert_annotations_to_yolo(input_dir: Path,
                           annotation_format: str = 'coco',
                           final_classes_order = None,
                           coco_task = 'detection',
                           coco_cls91to80 = False,
                               ):
       """
       统一的标注转换入口函数,根据指定的原始标注格式,调用相应的转换器
       :param input_dir: 原始标注文件路径
       :param annotation_format: 标注文件格式,coco, pascal_voc
       :param final_classes_order: 用户指定传入的classes列表
       :param coco_task: 仅当annotation_format为coco时,coco转换任务的类型
       :param coco_cls91to80: 是否将coco 91类映射 80类
       :return: data.yaml中的names列表
       """
       logger.info(f"开始处理原始标注数据: ({annotation_format.upper()})格式 路径为: {input_dir}")
   
       if not input_dir.exists():
           logger.error(f"输入标注目录: {input_dir} 不存在")
           raise FileNotFoundError(f"输入目录: {input_dir} 不存在")
       classes = []
   
       try:
           if annotation_format == "coco":
               if final_classes_order is not None:
                   logger.warning(f"COCO格式的标注数据不支持手动指定类别,目前仅支持自动提取类别")
                   classes = convert_coco_json_to_yolo(
                       json_input_dir=input_dir,
                       task=coco_task,
                       cls91to80=coco_cls91to80
                   )
           elif annotation_format == "pascal_voc":
               logger.info(f"开始转换Pascal VOC格式的标注数据")
               classes = convert_pascal_voc_to_yolo(
                   xml_input_dir=input_dir,
                   output_yolo_txt_dir=YOLO_STAGED_LABELS_DIR,
                   target_classes_for_yolo=final_classes_order
               )
               if not classes:
                   logger.error(f"转换Pascal VOC格式的标注数据时失败,为提取到任何类别")
                   return []
               logger.info(f"转换完成，转换的类别为：{classes}")
           else:
               logger.error(f"不支持的标注格式: {annotation_format},目前仅支持: 'coco' 或 'pascal_voc'")
               raise ValueError(f"不支持的标注格式: {annotation_format},目前仅支持: 'coco' 或 'pascal_voc'")
       except Exception as e:
           logger.critical(f"转换Pascal VOC格式的标注数据发生致命错误,"
                           f"格式{annotation_format},错误信息为: {e}",exc_info=True)
           classes = []
       if not classes:
           logger.warning(f"数据转换完成,但是未能确定任何可用的类别,请检查你的数据")
       logger.info(f"标注格式{annotation_format.upper()}转换处理完成")
       return classes
   ```

   



## 顶层脚本: `yolo_trans.py`放置在`scripts`目录里面

1.  支持命令行接口(CIL)做解析,

2. 调用data_utils实现转换

3. 数据集的组织与分割,将划分后图像和标签按照指定比例放置到 `train/images`,`train/labels`,`test/images`,`val/images`一共6个

4. 还需要能够自动生成data.yaml文件,内容如下，必须覆盖输出

5. 目录清理与初始化，每次运行前，清理之前的划分目录和data.yaml文件，确保每次运行都是干净的状态

6. 全面日志记录

7. 性能计时

8. 数据集划分可以采用

   ![image-20250624162723557](./image/image-20250624162723557.png)

```
path: C:\Users\Matri\Desktop\DTH2\yoloserver\data
train: C:\Users\Matri\Desktop\DTH2\yoloserver\data\train\images
val: C:\Users\Matri\Desktop\DTH2\yoloserver\data\val\images
test: C:\Users\Matri\Desktop\DTH2\yoloserver\data\test\images
nc: 3
names: [glioma_tumor, meningioma_tumor, pituitary_tumor]

```

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# @FileName  :yolo_trans.py
# @Time      :2025/6/25 09:20:53
# @Author    :雨霓同学
# @Project   :BTD
# @Function  :实现数据集的转换,分割，配置文件生成
import argparse
import sys
import yaml
import shutil
import logging
from pathlib import Path

current_path = Path(__file__).parent.parent.resolve()
utils_path = current_path / 'utils'
if str(current_path) not in sys.path:
    sys.path.insert(0, str(current_path))
if str(utils_path) not in sys.path:
    sys.path.insert(1, str(utils_path))

from sklearn.model_selection import train_test_split  #  pip install scikit-learn

from performance_utils import time_it
from paths import (YOLOSERVER_ROOT,
                RAW_IMAGES_DIR,
                ORIGINAL_ANNOTATIONS_DIR,
                YOLO_STAGED_LABELS_DIR,
                DATA_DIR,
                CONFIGS_DIR,
                LOGS_DIR
                )
from logging_utils import setup_logger
from data_utils import convert_annotations_to_yolo

logger = setup_logger(
    base_path=LOGS_DIR,
    log_type="yolo_trans",
    model_name=None,
    log_level=logging.INFO,
    logger_name="YOLO Trans"
)

class YOLODatasetProcessor:
    """
    一个集成类，负责
    1. 协调原始标注到YOLO TXT 格式的转换
    2. 划分原始图像和转换、复制后的YOLO TXT标签为训练集，验证集，测试集
    3. 生成data.yaml配置文件
    """
    def __init__(self,train_rate=0.8,valid_rate=0.1,annotation_format="coco",
                coco_task="detection",
                final_classes_order=None,
                coco_cls91to80=False):
        """
        初始化数据集处理器
        :param train_rate: 训练集的比例：默认0.8
        :param valid_rate: 验证集的比例：默认0.1
        """
        self.project_root_path = YOLOSERVER_ROOT
        self.raw_images_path = RAW_IMAGES_DIR
        self.yolo_staged_labels_dir = YOLO_STAGED_LABELS_DIR
        self.output_data_path = DATA_DIR
        self.config_path = CONFIGS_DIR
        self.classes = [] if final_classes_order is None else final_classes_order
        self.train_rate = train_rate
        self.valid_rate = valid_rate
        self.test_rate = 1 - train_rate - valid_rate
        self.annotation_format = annotation_format
        self.coco_task = coco_task
        self.coco_cls91to80 = coco_cls91to80


        # 确保数据集比例划分有效,这属于核心业务逻辑验证
        if not (0.0 <= self.train_rate <= 1.0 and
                0.0 <= self.valid_rate <= 1.0 and
                0.0 <= self.test_rate <= 1.0 and
                abs(self.train_rate + self.valid_rate + self.test_rate - 1.0) <= 1e-6):
            logger.error("训练集比例、验证集比例和测试集比例之和必须等于1.0,当前配置无效，请检查配置")
            raise ValueError("数据集比例配置无效/错误")

        self.config_path.mkdir(parents=True, exist_ok=True)
        self.output_dirs = {
            "train": {"images": self.output_data_path / "train" / "images",
                    "labels": self.output_data_path / "train" / "labels"},
            "val": {"images": self.output_data_path / "val" / "images",
                    "labels": self.output_data_path / "val" / "labels"},
            "test": {"images": self.output_data_path / "test" / "images",
                    "labels": self.output_data_path / "test" / "labels"}
                    }
    # 检查原始图像文件，以及转换之后的标注文件是否存在
    def _check_staged_data_existence(self):
        """
        检查转换后的数据集是否存在
        :return: True: 存在，False: 不存在
        """
        # 确保YOLO_STAGED_LABELS_DIR目录存在,且不为空，因为它直接影响后续的分割
        if not self.yolo_staged_labels_dir.exists() or not any(self.yolo_staged_labels_dir.glob("*.txt")):
            logger.error(f"转换后的YOLO TXT 文件目录{self.yolo_staged_labels_dir} "
                        f"中不存在 YOLO TXT 文件，请检查转换是否成功")
            raise FileNotFoundError(f"转换后的YOLO TXT 文件目录{self.yolo_staged_labels_dir} "
                        f"中不存在 YOLO TXT 文件，请检查转换是否成功")
        if not self.raw_images_path.exists() or not any(self.raw_images_path.glob("*.jpg")):
            logger.error(f"原始图像目录{self.raw_images_path} 中不存在图片文件，请检查原始数据集是否正确")
            raise FileNotFoundError(f"原始图像目录{self.raw_images_path} 中不存在图片文件，请检查原始数据集是否正确")
        logger.info(f"原始图像及标注文件暂存区通过检查："
                    f"图像位于 '{self.raw_images_path.relative_to(self.project_root_path)}'"
                    f"标签位于 '{self.yolo_staged_labels_dir.relative_to(self.project_root_path)}'")

    # 确保最终划分后的训练集，测试集，验证集的目录存在以及它们的子目录也存在
    def _ensure_output_dirs_exist(self):
        """
        确保最终划分后的训练集，测试集，验证集的目录存在以及它们的子目录也存在
        :return:
        """
        for split_info in self.output_dirs.values():
            for dir_path in split_info.values():
                dir_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"已创建目录或确认目录存在 '{dir_path.relative_to(self.project_root_path)}'")
        logger.info(f"所有输出数据集分割目录已准备就绪".center(60, "="))

    def _find_matching_files(self):
        """
        找到匹配的图像文件和对应的YOLO TXT文件
        :return: 匹配的图像文件的路径
        """
        txt_files = list(self.yolo_staged_labels_dir.glob("*.txt"))
        if not txt_files:
            logger.warning(f"未找到匹配的YOLO TXT文件，请检查转换是否成功")
            return []

        matching_pairs = []
        img_extensions = [".jpg", ".jpeg", ".png", "bmp", ".tiff", ".webp"]

        for txt_file in txt_files:
            found_image = False
            for ext in img_extensions:
                img_name_stem = txt_file.stem
                image_path = self.raw_images_path / (img_name_stem + ext)
                if image_path.exists():
                    matching_pairs.append((image_path, txt_file))
                    found_image = True
                    break
            if not found_image:
                logger.warning(f"未在 '{self.raw_images_path.relative_to(self.project_root_path)}' "
                            f"中找到匹配的图像文件: '{txt_file.name}'，跳过该标签文件")
        if not matching_pairs:
            logger.error(f"未找到匹配的图像文件，请检查原始数据集是否正确")
        else:
            logger.info(f"找到匹配的图像文件，共 {len(matching_pairs)} 个")
        return matching_pairs

    # 将数据集进行分割，分为训练集，测试集，验证集
    def _split_and_process_data(self,matching_pairs):
        """
        将数据集进行分割，分为训练集，测试集，验证集,并处理每个分割
        :param matching_pairs:
        :return:
        """
        if not matching_pairs:
            logger.error(f"没有数据可供划分，请检查原始数据集是否正确")
            return

        label_files = [pair[1] for pair in matching_pairs]
        image_files = [pair[0] for pair in matching_pairs]

        if len(matching_pairs) < 3:
            logger.warning(f"数据集样本数量太少：{len(matching_pairs)}，将无法进行有效分割,将所有数据划给训练集")
            self._process_single_split(label_files, image_files, "train")
            return

        # 第一次分割，训练集 vs 临时集 （验证集 + 测试集）
        train_labels, temp_labels, train_images, temp_images = train_test_split(label_files, image_files,
                                                test_size=self.test_rate,
                                                random_state=42,shuffle=True)
        val_labels, test_labels, val_images, test_images = [], [] , [] , []


        # 第二次分割，临时集 （验证集 + 测试集） 内部进行分割
        if temp_labels:
            remaining_rate = self.valid_rate +  self.test_rate
            if remaining_rate == 0 or len(temp_labels) < 2:
                val_labels, val_images = temp_labels, test_images
                logger.warning(f"临时数据集样本数量太少：{len(temp_labels)}，或剩余比例为0，"
                            f"将无法进行有效分割,将所有数据划给验证集")
            else:
                val_ratio_in_temp = self.valid_rate / remaining_rate
                if abs(val_ratio_in_temp) < 1e-6:
                    test_labels, test_images = temp_labels, temp_images
                    logger.info("验证集比例为0，所有剩余数据划给测试集")
                elif abs(val_ratio_in_temp - 1) < 1e-6:
                    val_labels, val_images = temp_labels, temp_images
                    logger.info("测试集比例为0，所有剩余数据划给验证集")
                else:
                    val_labels, test_labels, val_images, test_images = train_test_split(
                        temp_labels, temp_images,
                                test_size=val_ratio_in_temp,
                                random_state=42,shuffle=True)
        logger.info("数据集划分完成")
        logger.info(f"训练集样本数量：{len(train_labels)}")
        logger.info(f"验证集样本数量：{len(val_labels)}")
        logger.info(f"测试集样本数量：{len(test_labels)}")

        self._process_single_split(train_labels, train_images, "train")
        self._process_single_split(val_labels, val_images, "val")
        self._process_single_split(test_labels, test_images, "test")

    def _process_single_split(self, label_files, image_files, split_name):
        """
        处理单个数据集的划分,复制图像和YOLO TXT格式标签到指定的目录
        :param label_files:
        :param image_files:
        :param split_name:
        :return:
        """
        logger.info(f"开始处理：{split_name} 数据集,该数据集共{len(label_files)}个样本")
        target_img_dir = self.output_dirs[split_name]["images"]
        target_label_dir = self.output_dirs[split_name]["labels"]

        target_img_dir.mkdir(parents=True, exist_ok=True)
        target_label_dir.mkdir(parents=True, exist_ok=True)

        copied_images_count = 0
        failed_images_count = 0

        for image_path in image_files:
            new_img_path = target_img_dir / image_path.name
            try:
                shutil.copy(image_path, new_img_path)
                copied_images_count += 1
                logger.debug(f"成功复制图像文件 '{image_path.name}' "
                            f"到 '{new_img_path.relative_to(self.project_root_path)}'")
            except Exception as e:
                failed_images_count += 1
                logger.error(f"复制图像文件 '{image_path.name}' 到 "
                            f"'{new_img_path.relative_to(self.project_root_path)}' 失败: {e}")
        logger.info(f"{split_name} 数据集图像复制完成，成功复制 {copied_images_count} 张，"
                    f"失败复制图像 {failed_images_count} 张")

        copied_labels_count = 0
        failed_labels_count = 0

        for label_path in label_files:
            new_label_path = target_label_dir / label_path.name
            try:
                shutil.copy(label_path, new_label_path)
                copied_labels_count += 1
                logger.debug(f"成功复制标签文件 '{label_path.name}' "
                            f"到 '{new_label_path.relative_to(self.project_root_path)}'")
            except Exception as e:
                failed_labels_count += 1
                logger.debug(f"复制标签文件 '{label_path.name}' 到 "
                            f"'{new_label_path.relative_to(self.project_root_path)}' 失败: {e}")
        logger.info(f"{split_name} 数据集标签复制完成，成功复制标签 {copied_labels_count} 个，"
                    f"失败复制标签 {failed_labels_count} 个")

    def _generate_data_yaml(self):
        """
        生成yaml配置
        :return:
        """
        abs_data_path = self.output_data_path.absolute()
        train_images_abs_path = (self.output_dirs["train"]["images"]).resolve()
        val_images_abs_path = (self.output_dirs["val"]["images"]).resolve()
        test_images_abs_path = (self.output_dirs["test"]["images"]).resolve()

        data_yaml_content = {
            "path": str(abs_data_path),
            "train": str(train_images_abs_path),
            "val": str(val_images_abs_path),
            "test": str(test_images_abs_path),
            "nc": len(self.classes),
            "names": self.classes
        }
        yaml_path = self.config_path / "data.yaml"
        try:
            with open(yaml_path, "w", encoding="utf-8") as f:
                yaml.dump(data_yaml_content, f, default_flow_style=None, sort_keys=False, allow_unicode=True)
                logger.info(f"成功生成 data.yaml 文件：{yaml_path.relative_to(self.project_root_path)}")
                logger.info(f"data.yaml 文件内容："
                f"\n{yaml.dump(data_yaml_content,default_flow_style=None, sort_keys=False, allow_unicode=True)}")
        except Exception as e:
            logger.error(f"生成 data.yaml 文件失败: {e}")
            raise
    @time_it(iterations=1, name="数据集准备与划分", logger_instance=logger)
    def process_dataset(self,source_data_root_dir=ORIGINAL_ANNOTATIONS_DIR,):
        """
        执行整个数据集划分流程
        :param source_data_root_dir:
        :return:
        """
        logger.info("开始进行数据集准备与划分工作".center(60, "="))

        try:
            logger.info(f"处理原始标注数据：{self.annotation_format.upper()}格式")
            if self.annotation_format != "yolo":
                if self.yolo_staged_labels_dir.exists():
                    shutil.rmtree(self.yolo_staged_labels_dir)
                    logger.info(f"已经清理 YOLO 标签暂存目录: "
                                f"{self.yolo_staged_labels_dir.relative_to(self.project_root_path)}")
                    self.yolo_staged_labels_dir.mkdir(parents=True, exist_ok=True)
            if self.annotation_format == "yolo":
                if not self.classes:
                    logger.critical(f"当 annotation_format 为 yolo 是，请务必提供 classes 参数，数据集处理终止")
                    return

                self.yolo_staged_labels_dir = ORIGINAL_ANNOTATIONS_DIR
                logger.info(f"检测到原生的YOLO格式标注文件，YOLO暂存目录直接指向原始标注文件目录"
                        f"'{self.yolo_staged_labels_dir.relative_to(self.project_root_path)}'跳过复制步骤")

                if not any(self.yolo_staged_labels_dir.glob("*.txt")):
                    logger.critical(f"未检测到YOLO格式标注文件，请检查原始标注文件目录："
                                f"'{self.yolo_staged_labels_dir.relative_to(self.project_root_path)}'")
                    return

            elif self.annotation_format in ["coco", "pascal_voc"]:
                if not RAW_IMAGES_DIR.exists() or not any(RAW_IMAGES_DIR.iterdir()):
                    logger.critical(f"未检测到原始图像文件，请检查原始图像存放目录："
                                f"'{RAW_IMAGES_DIR.relative_to(self.project_root_path)}'")
                    return
                if not ORIGINAL_ANNOTATIONS_DIR.exists() or not any(ORIGINAL_ANNOTATIONS_DIR.iterdir()):
                    logger.critical(f"未检测到原始标注文件，请检查原始标注文件存放目录："
                                f"'{ORIGINAL_ANNOTATIONS_DIR.relative_to(self.project_root_path)}'")
                    return
                conversion_input_dir = source_data_root_dir
                self.classes = convert_annotations_to_yolo(
                    input_dir=conversion_input_dir,
                    annotation_format=self.annotation_format,
                    final_classes_order=self.classes if self.annotation_format == "pascal_voc" else None,
                    coco_task=self.coco_task,
                    coco_cls91to80=self.coco_cls91to80
                )
                # 检查最终地转换结果
                if not self.classes:
                    logger.critical(f"{self.annotation_format.upper()}转换失败或未提取到有效的类别信息，数据集处理终止")
                    return
                logger.info(f"{self.annotation_format.upper()}转换成功")
            else:
                logger.critical(f"不支持的标注格式：{self.annotation_format}，数据集处理终止")
                return

            # 调用检查脚本
            self._check_staged_data_existence()

            # 查找匹配的文件
            matching_pairs = self._find_matching_files()
            if not matching_pairs:
                logger.critical(f"未找到匹配的文件，数据集处理终止")
                return

            self._split_and_process_data(matching_pairs)

            # 生成 data.yaml 文件
            self._generate_data_yaml()
        except Exception as e:
            logger.error(f"数据集准备与划分过程发生严重错误: {e}",exc_info=True)
        finally:
            logger.info("数据集准备与划分工作完成".center(60, "="))

def _clean_and_initialize_dirs(processor_instance: YOLODatasetProcessor):
    logger.info("开始清理旧的数据集内容和配置文件".center(60, "="))

    for split_name,split_info in processor_instance.output_dirs.items():
        for dir_type, dir_path in split_info.items():
            if dir_path.exists():
                shutil.rmtree(dir_path, ignore_errors=True)
                logger.info(f"删除已经存在的 '{split_name}' {dir_type}目录：{dir_path.relative_to(YOLOSERVER_ROOT)}")
                dir_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"重新创建 '{split_name}' {dir_type}目录：{dir_path.relative_to(YOLOSERVER_ROOT)}")
    data_yaml_file = CONFIGS_DIR / "data.yaml"
    if data_yaml_file.exists():
        data_yaml_file.unlink()
        logger.info(f"删除已经存在的 data.yaml 文件：{data_yaml_file.relative_to(YOLOSERVER_ROOT)}")
    logger.info("旧数据集内容清理完成，新的目录结构创建完成".center(60, "="))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="YOLO 数据集处理工具",
                                formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    parser.add_argument("--format", type=str,
                        default="coco",
                        choices=["coco", "pascal_voc", "yolo"],
                        help="支持的数据集标注格式，coco, pascal_voc, yolo")

    parser.add_argument("--train_rate", type=float, default=0.8, help="训练集占比,默认0.8")
    parser.add_argument("--valid_rate", type=float, default=0.1, help="验证集占比,默认0.1")
    parser.add_argument("--classes",type=str,
                        nargs="+", # 允许一个或多个字符串作为列表
                        default=None,
                        help="类别名称列表，以空格分开，例如：--classes class1 class2 class3 \n"
                            "当 --format 为 yolo 时, 必须提供该参数"
                            "当 --format 为 coco 时， 此参数会被忽略"
                            "当 --format 为 pascal_voc 时，可选提供，不指定则使用自动模式"
                        )
    parser.add_argument("--coco_task", type=str,
                        default="segmentation",
                        choices=["detection", "segmentation"],
                        help="COCO任务类型，可选：detection, segmentation")
    parser.add_argument("--coco_cls91to80",default=False,
                        action="store_true", help="将COCO 91类映射 80类")

    args = parser.parse_args()

    processor = YOLODatasetProcessor(train_rate=args.train_rate,
                                    valid_rate=args.valid_rate,
                                    annotation_format=args.format,
                                    final_classes_order=args.classes,
                                    coco_task=args.coco_task,
                                    coco_cls91to80=args.coco_cls91to80
                                    )

    _clean_and_initialize_dirs(processor)

    processor.process_dataset()

    # 打印最终输出结果
    logger.info("所有数据处理流程完成，请检查以下路径文件")
    logger.info(f"训练集图像目录：{processor.output_dirs['train']['images'].relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"训练集标注文件：{processor.output_dirs['train']['labels'].relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"验证集图像目录：{processor.output_dirs['val']['images'].relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"验证集标注文件：{processor.output_dirs['val']['labels'].relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"测试集图像目录：{processor.output_dirs['test']['images'].relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"测试集标注文件：{processor.output_dirs['test']['labels'].relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"数据集配置文件：{processor.config_path.relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"详细的日志文件位于 {LOGS_DIR.relative_to(YOLOSERVER_ROOT)}")
    logger.info(f"接下来请执行数据验证脚本 yolo_validate.py 以验证数据转换是否正确")

```

##  数据验证

- 保证数据质量和一致性
  - 格式正确性： 确保YOLO标签文件的格式符合要求.
    - 检测任务：检测任务有5列值，坐标范围都在0-1之间
    - 分割任务：1 + N*2个值，其中坐标至少要大于3组。
  - 类别ID有效性：验证标签中类别ID是否在data.yaml中定义的有效范围，防止出现越界ID,
  - 图像-标签匹配问题，确认每张图片都有对应的标签，
- 避免数据泄露
  - 保证数据分割唯一性，确保训练集，测试集，验证集数据没有重叠，数据泄露是模型评估当中非常严重的错误，



### 核心结构划分

`utils/data_validation.py`：实现数据验证逻辑模块

- 保证数据质量和一致性
- 避免数据泄露

`scripts/yolo_validate.py`数据集验证入门脚本

- 随机抽取其中的一部分数据做验证，支持全量检测，和抽样检测
- 对于不合法的数据，信息做一个输出，然后输出异常数据数量，让用户自行决定是否删除异常数据。





## 模型训练需要支持的功能

1. 日志必不可少
2. 每次训练，都会生成递增目录，模型在weights文件夹中，一般有俩，一个bset,一个last,用户选择模型时，很不方便，因此考虑将所有训练好的模型放到指定的`yoloserver/models/checkpoints`然后模型的名称，命名为：trainN_年月日-时分秒-yolo11m-seg_best/last.pt
3. 用户选择预训练模型，在`yoloserver/models/pretrained`去找
4. 用户训练时，参数设定，至少让他支持CIL命令，然后支持YAML配置文件中的参数，命令行没有设置的参数，则使用YAML文件中的参数，用户训练过程中，所有的参数，记录到日志当中，参数来源应当有区分，必然会涉及参数合并，参数来源标记，参数的优先级。参数yaml文件的生成
5. 推理结果都保存和显示，推理结果需要记录到日志当中，（需要注意，分割和检测任务，结果是不一样的）

```
fitness: np.float64(0.9840878873578409)
keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'metrics/precision(M)', 'metrics/recall(M)', 'metrics/mAP50(M)', 'metrics/mAP50-95(M)']
maps: array([    0.95662,     0.90718,      0.9562])
names: {0: 'glioma_tumor', 1: 'meningioma_tumor', 2: 'pituitary_tumor'}
nt_per_class: array([12, 17,  9])
nt_per_image: array([12, 16,  9])
results_dict: {'metrics/precision(B)': np.float64(0.8098168107567217), 'metrics/recall(B)': np.float64(0.367217992516717), 'metrics/mAP50(B)': np.float64(0.6939525595316414), 'metrics/mAP50-95(B)': np.float64(0.4683357754870037), 'metrics/precision(M)': np.float64(0.8098168107567217), 'metrics/recall(M)': np.float64(0.367217992516717), 'metrics/mAP50(M)': np.float64(0.6869505703301636), 'metrics/mAP50-95(M)': np.float64(0.47166152937039674), 'fitness': np.float64(0.9840878873578409)}
save_dir: WindowsPath('runs/segment/yolo11mn-seg2')
seg: ultralytics.utils.metrics.Metric object
speed: {'preprocess': 0.16161081077518394, 'inference': 1.5760837838594879, 'loss': 0.0002459459505484414, 'postprocess': 2.525686486478662}
stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': [], 'tp_m': []}
task: 'segment'
模型存放点 runs\segment\yolo11mn-seg2
```

6. 训练过程中使用的数据信息，写入到日志当中
7. 训练过程中使用的设备信息，写入到日志当中
